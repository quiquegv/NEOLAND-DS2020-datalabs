{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adquisición de datos en Python - PRA02\n",
    "--------------------------------------\n",
    "\n",
    "\n",
    "En este Notebook encontraréis dos conjuntos de ejercicios: un primer conjunto de **ejercicios para practicar** y un segundo conjunto de **actividades evaluables** como PRÁCTICAS de la asignatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto el uso de la libería [Requests](http://docs.python-requests.org/) para realizar peticiones a web API de manera manual.\n",
    "\n",
    "Mediante esta librería podemos realizar solicitudes como en el ejemplo que hemos visto de [postcodes.io](http://postcodes.io).\n",
    "\n",
    "`response = requests.get('http://api.postcodes.io/postcodes/E98%201TT')`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Hemos visto que, en realizar una petición a una web API http, recuperamos un objeto que contiene, entre otros, los siguientes atributos: **status.code**, **content** y **headers**. Busca la información sobre los códigos de **status.code** y completa la siguiente tabla sobre los códigos de error http. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**\n",
    "\n",
    "Descripción de los principales códigos de error http:\n",
    "\n",
    "- 200: La solicitud se ha realizado con éxito.  \n",
    "- 301: Indica que la URL utilizada para realizar la consulta ha sido cambiada permanentemente. Es posible que nos devuelvan la nueva URL en la respuesta.  \n",
    "- 400: No se puedo interpretar la consulta por una sintaxis inválida.  \n",
    "- 401: Se requiere una autentificación para realizar la consulta.   \n",
    "- 403: Similar al error 401 pero no es posible en este caso obtener la autentificación de ninguna manera.  \n",
    "- 404: El servidor no pudo encontrar la información solicitada.  \n",
    "- 505: La versión HTTP usada en la consulta no es soportada por el servidor.\n",
    "- 501: El método de consulta usado no está soportado por el servidor.  \n",
    "\n",
    "Fuente: https://developer.mozilla.org/es/docs/Web/HTTP/Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio intentaremos hacer una solicitud a tres paginas web diferentes vía el protocolo http mediante el método GET implementado en `requests.get`.\n",
    "\n",
    "Obtén mediante `requests.get`, el contenido y el correspondiente `status.code` de las siguentes pàginas web: \n",
    "\n",
    "- http://google.com\n",
    "- http://wikipedia.org\n",
    "- https://mikemai.net/\n",
    "- http://google.com/noexisto\n",
    "\n",
    "Para cada web, muestra:\n",
    "\n",
    "- Los primeros 80 carácteres del contenido de la web \n",
    "- El código de `status.code`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo primero cargo la libreria\n",
    "import requests\n",
    "import json\n",
    "import tweepy\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta\n",
    "google = requests.get('http://google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"es\"\n"
     ]
    }
   ],
   "source": [
    "google_text = google.text\n",
    "print(google_text[0:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta\n",
    "wikipedia = requests.get('http://wikipedia.org')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"mul\" class=\"no-js\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\">\n",
      "<t\n"
     ]
    }
   ],
   "source": [
    "wikipedia_text = wikipedia.text\n",
    "print(wikipedia_text[0:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mikemai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mikemai = requests.get('https://mikemai.net/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mikemai.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title>Not Acceptable!</title><script src=\"/cdn-cgi/apps/head/Z5kPjcSfsgqj\n"
     ]
    }
   ],
   "source": [
    "mikemai_text = mikemai.text\n",
    "print(mikemai_text[0:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google - no existo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_existo = requests.get('http://google.com/noexisto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_existo.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=en>\n",
      "  <meta charset=utf-8>\n",
      "  <meta name=viewport cont\n"
     ]
    }
   ],
   "source": [
    "no_existo_text = no_existo.text\n",
    "print(no_existo_text[0:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "En este ejercicio vamos a hacer un poco de *Fun with cats*. Existe una API para *cat-facts* (hechos sobre gatos) en la base de https://cat-fact.herokuapp.com. Esta API tiene dos puntos de acceso:\n",
    "\n",
    "- **/facts**\n",
    "- **/users**\n",
    "\n",
    "Según la documentación, el modelo en el punto de entrada de un **fact** es tal y como se indica a continuación: \n",
    "\n",
    "|    Key    |      Type     |                                              Description                                              |   |   |\n",
    "|:---------:|:-------------:|:-----------------------------------------------------------------------------------------------------:|---|---|\n",
    "| _id       | ObjectId      | Unique ID for the Fact                                                                                |   |   |\n",
    "| _v        | Number        | Version number of the Fact                                                                            |   |   |\n",
    "| user      | ObjectId      | ID of the User who added the Fact                                                                     |   |   |\n",
    "| text      | String        | The Fact itself                                                                                       |   |   |\n",
    "| updatedAt | Timestamp     | Date in which Fact was last modified                                                                  |   |   |\n",
    "| sendDate  | Timestamp     | If the Fact is meant for one time use, this is the date that it is used                               |   |   |\n",
    "| deleted   | Boolean       | Whether or not the Fact has been deleted (Soft deletes are used)                                      |   |   |\n",
    "| source    | String (enum) | Can be 'user' or 'api', indicates who added the fact to the DB                                        |   |   |\n",
    "| used      | Boolean       | Whether or not the Fact has been sent by the CatBot. This value is reset each time every Fact is used |   |   |\n",
    "| type      | String        | Type of animal the Fact describes (e.g. ‘cat’, ‘dog’, ‘horse’)                                        |   |   |\n",
    "\n",
    "Así, para obtener el **fact** número *58e0086f0aac31001185ed02*, debemos construir una solicitud a la url:\n",
    "\n",
    "- *https://cat-fact.herokuapp.com/facts/58e0086f0aac31001185ed02*\n",
    "\n",
    "El objecto que se nos devolverá, contendrá la información indicada en la tabla en formato *json* serializado. \n",
    "\n",
    "a) Contruye la solicitud, convierte el resultado a un diccionario y muestra por pantalla el resultado de los valores de la tabla anterior para el fact id *58e0086f0aac31001185ed02*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Respuesta\n",
    "cat_fact_1 = requests.get('https://cat-fact.herokuapp.com/facts/58e0086f0aac31001185ed02')\n",
    "cat_fact_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"status\":{\"verified\":true,\"sentCount\":1},\"type\":\"cat\",\"deleted\":false,\"_id\":\"58e0086f0aac31001185ed02\",\"user\":{\"name\":{\"first\":\"Kasimir\",\"last\":\"Schulz\"},\"photo\":\"https://lh6.googleusercontent.com/-BS_rskGd3kA/AAAAAAAAAAI/AAAAAAAAADg/yAxrX9QabMg/photo.jpg?sz=200\",\"_id\":\"58e007480aac31001185ecef\"},\"text\":\"Cats can\\'t taste sweetness.\",\"__v\":0,\"source\":\"https://www.scientificamerican.com/article/strange-but-true-cats-cannot-taste-sweets/\",\"updatedAt\":\"2020-08-29T20:20:03.172Z\",\"createdAt\":\"2018-03-16T20:20:03.622Z\",\"used\":true}'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_fact_1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': {'verified': True, 'sentCount': 1},\n",
       " 'type': 'cat',\n",
       " 'deleted': False,\n",
       " '_id': '58e0086f0aac31001185ed02',\n",
       " 'user': {'name': {'first': 'Kasimir', 'last': 'Schulz'},\n",
       "  'photo': 'https://lh6.googleusercontent.com/-BS_rskGd3kA/AAAAAAAAAAI/AAAAAAAAADg/yAxrX9QabMg/photo.jpg?sz=200',\n",
       "  '_id': '58e007480aac31001185ecef'},\n",
       " 'text': \"Cats can't taste sweetness.\",\n",
       " '__v': 0,\n",
       " 'source': 'https://www.scientificamerican.com/article/strange-but-true-cats-cannot-taste-sweets/',\n",
       " 'updatedAt': '2020-08-29T20:20:03.172Z',\n",
       " 'createdAt': '2018-03-16T20:20:03.622Z',\n",
       " 'used': True}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_fact_1_dict = json.loads(cat_fact_1.text)\n",
    "cat_fact_1_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Para ara los fact ids:\n",
    "\n",
    "- *5d38bdab0f1c57001592f156*\n",
    "- *5ed11e643c15f700172e3856*\n",
    "- *5ef556dff61f300017030d4c*\n",
    "- *5d9d4ae168a764001553b388*\n",
    "\n",
    "Obtén campos *type*, *user*, *user*, *source*, *used*, *text* y imprímelos siguiendo el siguiente formato:\n",
    "\n",
    "\n",
    "`Type: cat\tUser: 58e007480aac31001185ecef\n",
    "Used: True\tId: 58e0086f0aac31001185ed02\n",
    "Source: https://www.scientificamerican.com/article/strange-but-true-cats-cannot-taste-sweets/\n",
    "Text: Cats can't taste sweetness.`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a crear una función para obtener los datos en ese formato\n",
    "def get_catfacts(fact_Id):\n",
    "    cat_fact = requests.get('https://cat-fact.herokuapp.com/facts/'+str(fact_Id))\n",
    "    cat_fact = json.loads(cat_fact.text)\n",
    "    # Imprimo los valores que piden. En el apartado user, le digo que solamente imprima el _id\n",
    "    print('Type: '+str(cat_fact['type'])+'\\t User: '+str(cat_fact['user']['_id']) + '\\n'+\n",
    "         'Used: '+str(cat_fact['used'])+'\\t Id: '+str(cat_fact['_id']) + '\\n'+\n",
    "         'Source: '+str(cat_fact['source'])+'\\n'+\n",
    "         'Text: '+str(cat_fact['text'])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: cat\t User: 5a9ac18c7478810ea6c06381\n",
      "Used: False\t Id: 5d38bdab0f1c57001592f156\n",
      "Source: user\n",
      "Text: While some cats love being brushed, others don't take to it naturally. Try to groom your cat in the same spot at the same time of day to create a sense of routine.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_catfacts('5d38bdab0f1c57001592f156')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: cat\t User: 5ed11e353c15f700172e3855\n",
      "Used: False\t Id: 5ed11e643c15f700172e3856\n",
      "Source: user\n",
      "Text: Los gatos tienen más huesos que los seres humanos, nos ganan por 24.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_catfacts('5ed11e643c15f700172e3856')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: cat\t User: 5e1a9b981fd6150015fa736f\n",
      "Used: False\t Id: 5ef556dff61f300017030d4c\n",
      "Source: user\n",
      "Text: Lucy, the oldest cat ever, lived to be 39 years old which is equivalent to 172 cat years.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_catfacts('5ef556dff61f300017030d4c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: cat\t User: 5d9d4a4468a764001553b387\n",
      "Used: False\t Id: 5d9d4ae168a764001553b388\n",
      "Source: user\n",
      "Text: Cats conserve energy by sleeping for an average of 13 to 14 hours a day.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_catfacts('5d9d4ae168a764001553b388')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "En los ejercicios anteriores, usamos directamente una API para hacer la solicitud que requiramos, y nos encargamos directamente de la gestión de los datos de salida. \n",
    "\n",
    "No obstante, hemos visto ya el uso de librerías que facilitan el accesso a una API. La mayoría de estas librerías (y APIs de proyectos populares) requieren de un registro en la web de desarolladores. \n",
    "\n",
    "\n",
    "Sigue la documentación proporcionada en clase para conseguir un registro en el panel de desarolladores de Twitter. Obtendrás 4 códigos para autenticar tu aplicación. \n",
    "\n",
    "Usa la librería **tweepy** para programar dos funciones. \n",
    "\n",
    "- La primera función, se autentica en la API de twitter usando los 4 códigos proporcionados por el registro. A partir de un nombre de usuario en twitter proporcionado en el argumento de la función, esta retorna una tupla `(user, api)` con el objeto `twepy.models.User`, correspondiente a ese usuario y el descriptor de la API ya inicializada. \n",
    "- La segunda funcion, aceptará un objeto  `twepy.models.User` de entrada y imprimirá: \n",
    " 1. El número de tweets del usuario.\n",
    " 1. El número de amigos del usuario.\n",
    " 1. El número de seguidores del usuario.\n",
    " 1. Los nombres de pantalla de los primeros 10 amigos del usuario (`screen_name`), sus nombres (`name`) junto con sus descripciones.\n",
    "\n",
    "Ejecuta las dos funciones sobre el usuario de twitter **Space_Station**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta\n",
    "# Lo primero cargo las credenciales de twitter \n",
    "CONSUMER_KEY= \"\"\n",
    "CONSUMER_SECRET=\"\"\n",
    "ACCESS_TOKEN=\"\"\n",
    "ACCESS_SECRET=\"\"\n",
    "# he ejecutado el codigo con las credenciales, al subirlo las he borrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función\n",
    "def get_tw_api_user(user_name):\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET) # con esto lo que hacemos es meter las claves en una variable que servirán para autentificarnos.\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "    # obtengo la API que me permite hacer las consultas\n",
    "    api = tweepy.API(auth)\n",
    "    # busco los datos del usuario\n",
    "    user = api.get_user(\"Space_Station\")\n",
    "    return (user,api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(User(_api=<tweepy.api.API object at 0x7fcde41e5220>, _json={'id': 1451773004, 'id_str': '1451773004', 'name': 'International Space Station', 'screen_name': 'Space_Station', 'location': 'Low Earth Orbit', 'profile_location': None, 'description': \"NASA's page for updates from the International Space Station, the world-class lab orbiting Earth 250 miles above. For the latest research, follow @ISS_Research.\", 'url': 'https://t.co/9Gk2H0gekn', 'entities': {'url': {'urls': [{'url': 'https://t.co/9Gk2H0gekn', 'expanded_url': 'http://www.nasa.gov/station', 'display_url': 'nasa.gov/station', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 4157142, 'friends_count': 219, 'listed_count': 12734, 'created_at': 'Thu May 23 15:25:28 +0000 2013', 'favourites_count': 18316, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': True, 'statuses_count': 13715, 'lang': None, 'status': {'created_at': 'Mon Jan 04 03:42:01 +0000 2021', 'id': 1345938510868525061, 'id_str': '1345938510868525061', 'text': '@polishpiperrick The go around the world every 90 minutes and see one sunrise and one sunset each orbit.', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'polishpiperrick', 'name': 'Ricky', 'id': 1220518819418066945, 'id_str': '1220518819418066945', 'indices': [0, 16]}], 'urls': []}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>', 'in_reply_to_status_id': 1345133512115048451, 'in_reply_to_status_id_str': '1345133512115048451', 'in_reply_to_user_id': 1220518819418066945, 'in_reply_to_user_id_str': '1220518819418066945', 'in_reply_to_screen_name': 'polishpiperrick', 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 1, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'C0DEED', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1189945624583720960/k6MtoeIt_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1189945624583720960/k6MtoeIt_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1451773004/1572540103', 'profile_link_color': '0084B4', 'profile_sidebar_border_color': 'FFFFFF', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, id=1451773004, id_str='1451773004', name='International Space Station', screen_name='Space_Station', location='Low Earth Orbit', profile_location=None, description=\"NASA's page for updates from the International Space Station, the world-class lab orbiting Earth 250 miles above. For the latest research, follow @ISS_Research.\", url='https://t.co/9Gk2H0gekn', entities={'url': {'urls': [{'url': 'https://t.co/9Gk2H0gekn', 'expanded_url': 'http://www.nasa.gov/station', 'display_url': 'nasa.gov/station', 'indices': [0, 23]}]}, 'description': {'urls': []}}, protected=False, followers_count=4157142, friends_count=219, listed_count=12734, created_at=datetime.datetime(2013, 5, 23, 15, 25, 28), favourites_count=18316, utc_offset=None, time_zone=None, geo_enabled=False, verified=True, statuses_count=13715, lang=None, status=Status(_api=<tweepy.api.API object at 0x7fcde41e5220>, _json={'created_at': 'Mon Jan 04 03:42:01 +0000 2021', 'id': 1345938510868525061, 'id_str': '1345938510868525061', 'text': '@polishpiperrick The go around the world every 90 minutes and see one sunrise and one sunset each orbit.', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'polishpiperrick', 'name': 'Ricky', 'id': 1220518819418066945, 'id_str': '1220518819418066945', 'indices': [0, 16]}], 'urls': []}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>', 'in_reply_to_status_id': 1345133512115048451, 'in_reply_to_status_id_str': '1345133512115048451', 'in_reply_to_user_id': 1220518819418066945, 'in_reply_to_user_id_str': '1220518819418066945', 'in_reply_to_screen_name': 'polishpiperrick', 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 1, 'favorited': False, 'retweeted': False, 'lang': 'en'}, created_at=datetime.datetime(2021, 1, 4, 3, 42, 1), id=1345938510868525061, id_str='1345938510868525061', text='@polishpiperrick The go around the world every 90 minutes and see one sunrise and one sunset each orbit.', truncated=False, entities={'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'polishpiperrick', 'name': 'Ricky', 'id': 1220518819418066945, 'id_str': '1220518819418066945', 'indices': [0, 16]}], 'urls': []}, source='Twitter Web App', source_url='https://mobile.twitter.com', in_reply_to_status_id=1345133512115048451, in_reply_to_status_id_str='1345133512115048451', in_reply_to_user_id=1220518819418066945, in_reply_to_user_id_str='1220518819418066945', in_reply_to_screen_name='polishpiperrick', geo=None, coordinates=None, place=None, contributors=None, is_quote_status=False, retweet_count=0, favorite_count=1, favorited=False, retweeted=False, lang='en'), contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='C0DEED', profile_background_image_url='http://abs.twimg.com/images/themes/theme1/bg.png', profile_background_image_url_https='https://abs.twimg.com/images/themes/theme1/bg.png', profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1189945624583720960/k6MtoeIt_normal.jpg', profile_image_url_https='https://pbs.twimg.com/profile_images/1189945624583720960/k6MtoeIt_normal.jpg', profile_banner_url='https://pbs.twimg.com/profile_banners/1451773004/1572540103', profile_link_color='0084B4', profile_sidebar_border_color='FFFFFF', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=False, default_profile=False, default_profile_image=False, following=False, follow_request_sent=False, notifications=False, translator_type='none'),\n",
       " <tweepy.api.API at 0x7fcde41e5220>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tw_api_user(\"Space_Station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_tw_data(user_name):\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET) # con esto lo que hacemos es meter las claves en una variable que servirán para autentificarnos.\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "    # obtengo la API que me permite hacer las consultas\n",
    "    api = tweepy.API(auth)\n",
    "    # busco los datos del usuario\n",
    "    user = api.get_user(user_name)\n",
    "    # finalmente le digo que me devuelva los valores pedidos: \n",
    "    print(\"El numero de Tweets: {}\".format(user.statuses_count))\n",
    "    print(\"El numero de amigos: {}\".format(user.friends_count))\n",
    "    print(\"El numero de followers: {}\".format(user.followers_count))\n",
    "    # para obtener los amigos uso friends_ids que obtiene los Ids de todos los amigos de un usario concreto. Selecciono los diez primeros. \n",
    "    friends = api.friends_ids(user_name)[0:10]\n",
    "    # posteriormente hago un for que recorra la lista y muestro los valores que se pude, screen_name, name y descripción. \n",
    "    for friend in friends:\n",
    "        user1 = api.get_user(friend)\n",
    "        print(\"\\n\" + user1.screen_name + \"\\n\" + user1.name + \"\\n\" + user1.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de Tweets: 13715\n",
      "El numero de amigos: 219\n",
      "El numero de followers: 4157230\n",
      "\n",
      "Explorer_Flight\n",
      "Zebulon Scoville\n",
      "86th NASA Flight Director. Lucky husband and father. Always looking for a challenge. Tweets are my own, so don't blame NASA.\n",
      "\n",
      "Astro_Stephanie\n",
      "Stephanie Wilson\n",
      "\n",
      "\n",
      "jmorhard\n",
      "Jim Morhard\n",
      "Serving as @NASA's Deputy Administrator, working to support the agency's many missions including space exploration, Earth sciences, and aeronautics.\n",
      "\n",
      "Astro_CabanaBob\n",
      "Bob Cabana\n",
      "Former astronaut and current Center Director of Kennedy Space Center.\n",
      "\n",
      "KudSverchkov\n",
      "Sergey Kud-Sverchkov\n",
      "Космонавт Роскосмоса (@Roscosmos) Сергей Кудь-Сверчков\n",
      "//\n",
      "@Roscosmos cosmonaut Sergey Kud-Sverchkov\n",
      "\n",
      "US_SpaceCom\n",
      "U.S. Space Command\n",
      "The OFFICIAL Twitter Page of United States Space Command, the 11th Combatant Command in the Department of Defense. #USSPACECOM\n",
      "\n",
      "Astro_Kutryk\n",
      "Joshua Kutryk\n",
      "Canadian Space Agency Astronaut and RCAF Test Pilot.\n",
      "\n",
      "ivan_mks63\n",
      "Ivan Vagner\n",
      "Космонавт Роскосмоса (@Roscosmos) Иван Вагнер\n",
      "//\n",
      "@Roscosmos cosmonaut Ivan Vagner\n",
      "\n",
      "Astro_Megan\n",
      "Megan McArthur\n",
      "NASA Astronaut and veteran of Space Shuttle mission STS-125.\n",
      "\n",
      "AstroJaws\n",
      "Jasmin Moghbeli\n",
      "Marine Attack Helicopter Pilot. Test Pilot. NASA Astronaut. Auntie to some ridiculously cool kids. Excited to share my journey!\n"
     ]
    }
   ],
   "source": [
    "get_user_tw_data(\"Space_Station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5\n",
    "\n",
    "[congreso.es](http://www.congreso.es/) es la página web del Congreso de los Diputados en España. En ella se guarda una relación de todos los diputados elegidos en cada una de las legislaturas. \n",
    "\n",
    "En una de las páginas se puede observar un mapa del hemiciclo, junto con la posición de cada uno de los diputados, su fotografía, su representación territorial y el partido político al que esté adscrito.  Esta url se encuentra en [Hemiciclo](http://www.congreso.es/portal/page/portal/Congreso/Congreso/Diputados/Hemiciclo).\n",
    "\n",
    "Usad `scrappy` para extraer la siguiente información:\n",
    "\n",
    "*Nombre*, *Territorio*, *Partido*, *URL Imagen*, en el formato de un diccionario, como por ejemplo:\n",
    "\n",
    "`{'Nombre': 'Callejas Cano, Juan Antonio ', 'Territorio': 'Diputado por Ciudad Real', 'Partido': 'G.P. Popular en el Congreso', 'url': '/wc/htdocs/web/img/diputados/peq/35_14.jpg'}`\n",
    "\n",
    "Para Ello: \n",
    "\n",
    "- Utilizad el tutorial de scrappy para encontrar un `xpath` que contenga la información requerida\n",
    "- Extraed la información requerida en forma de diccionario.\n",
    "\n",
    "**Nota**: si la ejecución del _crawler_ os devuelve un error `ReactorNotRestartable`, reiniciad el núcleo del Notebook (en el menú: `Kernel` - `Restart`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta\n",
    "# creamos primero el bicho \"araña\"\n",
    "class congreso_spider(scrapy.Spider):\n",
    "    # Asignamos un nombre al bicho\n",
    "    name = \"congreso_spider\"\n",
    "    \n",
    "    # Indicamos la url que queremos analizar\n",
    "    start_urls = [\n",
    "        \"https://www.congreso.es/web/guest/busqueda-de-diputados\"\n",
    "    ]\n",
    "    \n",
    "    # Definimos el analizador\n",
    "    def parse(self, response):\n",
    "        for diputado in response.xpath('/html/body/div[1]/div[2]/div[1]/div[2]/section/div/div[2]/div[2]/div/div/section/div/div[2]/div/div[1]/div/div/div[2]/div[2]/table'):\n",
    "            yield {\n",
    "                'Nombre': diputado.extract(),\n",
    "                'Terrotorio': territorio.extract(),\n",
    "                'Partido': partido.extract()\n",
    "                \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-08 16:30:35 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
      "2021-01-08 16:30:36 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.8.6 | packaged by conda-forge | (default, Oct  7 2020, 19:08:05) - [GCC 7.5.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.2.1, Platform Linux-4.15.0-128-generic-x86_64-with-glibc2.10\n",
      "2021-01-08 16:30:36 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2021-01-08 16:30:36 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n",
      "2021-01-08 16:30:36 [scrapy.extensions.telnet] INFO: Telnet Password: 33382e69e5123ff3\n",
      "2021-01-08 16:30:36 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-01-08 16:30:36 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-01-08 16:30:36 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-01-08 16:30:36 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-01-08 16:30:36 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-01-08 16:30:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-01-08 16:30:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-01-08 16:30:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.congreso.es/web/guest/busqueda-de-diputados> (referer: None)\n",
      "2021-01-08 16:30:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2021-01-08 16:30:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 266,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 31209,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.897919,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2021, 1, 8, 16, 30, 36, 985224),\n",
      " 'log_count/DEBUG': 1,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 93691904,\n",
      " 'memusage/startup': 93691904,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2021, 1, 8, 16, 30, 36, 87305)}\n",
      "2021-01-08 16:30:36 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Creamos un crawler.\n",
    "    process = CrawlerProcess({\n",
    "        'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)',\n",
    "        'DOWNLOAD_HANDLERS': {'s3': None},\n",
    "        'LOG_ENABLED': True\n",
    "    })\n",
    "\n",
    "    # Inicializamos el crawler con nuestra araña.\n",
    "    process.crawl(congreso_spider)\n",
    "    \n",
    "    # Lanzamos la araña.\n",
    "    process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scrapy.crawler.CrawlerProcess at 0x7f98caa79ee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio opcional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consultad la paǵina web de Open Notify, indicando la información sobre los humanos residentes fuera de la tierra (es decir, en el espacio). Dirección url en  [Open Notify](http://api.open-notify.org).\n",
    "\n",
    "Codificad una función que imprima por pantalla el número total de astronautas en el espacio, numero de naves tripuladas actualmente en órbita, así como el nombre de los astronautas que habitan para cada una de estas naves. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Respuesta\n",
    "datos_iss = requests.get('http://api.open-notify.org/astros.json')\n",
    "datos_iss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sergey Ryzhikov'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_iss_dict = json.loads(datos_iss.text)\n",
    "datos_iss_dict['people'][0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es contar el numero de 'craft' diferentes que hay, así como el numero de astronautas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names_iss(dict): # coge un diccionario. \n",
    "    nombres = [] # creo una lista donde meteré los nombres\n",
    "    category1 = list(dict)[2] # la variable categoría 1 cogerá el elemento número 2 del dict de la ISS, que es 'people'\n",
    "    for i in range(0, len(dict[category1])): # hago un for que va a recorrer 'people'.\n",
    "        category2 = list(dict[category1][i]) # creo una variable que dentro de 'people' va a convertir en lista cada una de las filas, devolverá 'craft' y 'name'\n",
    "        nombres.append(dict[category1][i][category2[1]])  # que de cada posición i de 'people' me de el valor 1 de la category2 que es name. Es decir me da los nombres y los añado a nombres\n",
    "    return nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ships_iss(dict): # coge un diccionario. \n",
    "    ships = [] # creo una lista donde meteré los nombres\n",
    "    category1 = list(dict)[2] # la variable categoría 1 cogerá el elemento número 2 del dict de la ISS, que es 'people'\n",
    "    for i in range(0, len(dict[category1])): # hago un for que va a recorrer 'people'.\n",
    "        category2 = list(dict[category1][i]) # creo una variable que dentro de 'people' va a convertir en lista cada una de las filas, devolverá 'craft' y 'name'\n",
    "        ships.append(dict[category1][i][category2[0]])  # que de cada posición i de 'people' me de el valor 1 de la category2 que es name. Es decir me da los nombres y los añado a nombres\n",
    "    return ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Kate Rubins', 'Mike Hopkins', 'Sergey Kud-Sverchkov',\n",
       "       'Sergey Ryzhikov', 'Shannon Walker', 'Soichi Noguchi',\n",
       "       'Victor Glover'], dtype='<U20')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(get_names_iss(datos_iss_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def people_space(URL):\n",
    "    datos = requests.get(URL)\n",
    "    datosdict = json.loads(datos_iss.text)\n",
    "    astronautas = get_names_iss(datosdict)\n",
    "    naves = get_ships_iss(datosdict)\n",
    "    print('El numero de naves es {} y numero total de astonautas es {}'.format(len(np.unique(naves)),len(np.unique(astronautas))))\n",
    "    for nave in np.unique(naves):\n",
    "        astronautas_nave = []\n",
    "        for astronauta in range(0,len(astronautas)):\n",
    "            if datosdict['people'][astronauta]['craft'] == nave:\n",
    "                astronautas_nave.append(datosdict['people'][astronauta]['name'])\n",
    "        print('Los astronautas de la nave '+str(nave)+' son: {}'.format(astronautas_nave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de naves es 1 y numero total de astonautas es 7\n",
      "Los astronautas de la nave ISS son: ['Sergey Ryzhikov', 'Kate Rubins', 'Sergey Kud-Sverchkov', 'Mike Hopkins', 'Victor Glover', 'Shannon Walker', 'Soichi Noguchi']\n"
     ]
    }
   ],
   "source": [
    "people_space('http://api.open-notify.org/astros.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
