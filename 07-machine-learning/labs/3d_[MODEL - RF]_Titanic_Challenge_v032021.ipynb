{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling - Titanic Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalamos la librería de kaggle API\n",
    "!pip install kaggle -q # -q sería quiet es decir que no deja rastro de lo que instala...a veces es útil ocultarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/kaggle.json': No such file or directory\n",
      "kaggle.json\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp /kaggle.json ~/.kaggle/ # en caso de Google Colab \n",
    "!ls ~/.kaggle\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod 600 ~/.kaggle/kaggle.json # directorio que apunta a la raíz en Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jovyan/.kaggle/kaggle.json'\n",
      "usage: kaggle [-h] [-v] {competitions,c,datasets,d,kernels,k,config} ...\n",
      "kaggle: error: the following arguments are required: command\n"
     ]
    }
   ],
   "source": [
    "!kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos las librerías\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "from scipy.stats import norm, skew\n",
    "from scipy import stats\n",
    "import xlrd, xdrlib\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# data mining\n",
    "#from sklearn.impute import KNNImputer, MissingIndicator, SimpleImputer\n",
    "from sklearn import impute\n",
    "#from sklearn_pandas import categorical_imputer, CategoricalImputer\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# machine learning\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "## scikit modeling libraries\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\n",
    "                             GradientBoostingClassifier, ExtraTreesClassifier,\n",
    "                             VotingClassifier)\n",
    "\n",
    "from sklearn.model_selection import (GridSearchCV, cross_val_score, cross_val_predict,\n",
    "                                     StratifiedKFold, learning_curve)\n",
    "\n",
    "## Load metrics for predictive modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.feature_selection import RFE, rfe\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "## Warnings and other tools\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 5. Model, predict and solve the problem.\n",
    "### 5.1 Modelos de clasificación standalone\n",
    "### 5.2 Modelos de clasificación con CV (Cross Validation)\n",
    "#### 5.2.1 - K-fold Cross Validation\n",
    "#### **5.2.2 - Ajustes de parámetros del CV**\n",
    "#### 5.2.3 - Ajuste de Hyperparámetros (modelos ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1 - k-fold Cross Validation\n",
    "\n",
    "K-Folds cross-validator\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html?highlight=k%20fold#sklearn.model_selection.KFold\n",
    "\n",
    "Provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds (without shuffling by default).\n",
    "\n",
    "Each fold is then used once as a validation while the k - 1 remaining folds form the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Validation Set\n",
    "\n",
    "Al entrenar un modelo, el uso de diferentes parámetros puede conducir a una solución muy diferente. Con el fin de evitar de minimizar el error, que no siempre es un buen punto de partida, creamos una solución de **conjunto de validación**, que nos sirve para validar la selección de parámetros. Difiere del **conjunto de prueba o test** que este sirve solo para validar la calidad del modelo.\n",
    "\n",
    "![](https://miro.medium.com/max/1552/1*Nv2NNALuokZEcV6hYEHdGA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>InCabin</th>\n",
       "      <th>Room</th>\n",
       "      <th>Title</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Fare_Per_Person</th>\n",
       "      <th>...</th>\n",
       "      <th>Deck_N</th>\n",
       "      <th>Deck_T</th>\n",
       "      <th>AgeGroup_Adult</th>\n",
       "      <th>AgeGroup_Baby</th>\n",
       "      <th>AgeGroup_Child</th>\n",
       "      <th>AgeGroup_Senior</th>\n",
       "      <th>AgeGroup_Student</th>\n",
       "      <th>AgeGroup_Teenager</th>\n",
       "      <th>AgeGroup_Unknown</th>\n",
       "      <th>AgeGroup_Young Adult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8419</td>\n",
       "      <td>0</td>\n",
       "      <td>2.178064</td>\n",
       "      <td>-0.5583</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.6862</td>\n",
       "      <td>1.4286</td>\n",
       "      <td>-0.1562</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8419</td>\n",
       "      <td>1</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.9323</td>\n",
       "      <td>2.4026</td>\n",
       "      <td>-1.0623</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.3521</td>\n",
       "      <td>0</td>\n",
       "      <td>2.369075</td>\n",
       "      <td>-0.5583</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.6862</td>\n",
       "      <td>1.9611</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8419</td>\n",
       "      <td>0</td>\n",
       "      <td>2.268252</td>\n",
       "      <td>-0.5583</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.6862</td>\n",
       "      <td>0.8443</td>\n",
       "      <td>-0.0530</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8419</td>\n",
       "      <td>1</td>\n",
       "      <td>2.586824</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.9323</td>\n",
       "      <td>0.4547</td>\n",
       "      <td>-1.1686</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex      Fare  FamilySize  IsAlone  InCabin  Room   Title  \\\n",
       "0  0.8419    0  2.178064     -0.5583        1    False  -0.0  0.6862   \n",
       "1  0.8419    1  2.079442      0.0734        0    False  -0.0 -0.9323   \n",
       "2 -0.3521    0  2.369075     -0.5583        1    False  -0.0  0.6862   \n",
       "3  0.8419    0  2.268252     -0.5583        1    False  -0.0  0.6862   \n",
       "4  0.8419    1  2.586824      0.7051        0    False  -0.0 -0.9323   \n",
       "\n",
       "   Age*Class  Fare_Per_Person  ...  Deck_N  Deck_T  AgeGroup_Adult  \\\n",
       "0     1.4286          -0.1562  ...       1       0               0   \n",
       "1     2.4026          -1.0623  ...       1       0               1   \n",
       "2     1.9611           0.0624  ...       1       0               0   \n",
       "3     0.8443          -0.0530  ...       1       0               0   \n",
       "4     0.4547          -1.1686  ...       1       0               0   \n",
       "\n",
       "   AgeGroup_Baby  AgeGroup_Child  AgeGroup_Senior  AgeGroup_Student  \\\n",
       "0              0               0                0                 0   \n",
       "1              0               0                0                 0   \n",
       "2              0               0                1                 0   \n",
       "3              0               0                0                 0   \n",
       "4              0               0                0                 1   \n",
       "\n",
       "   AgeGroup_Teenager  AgeGroup_Unknown  AgeGroup_Young Adult  \n",
       "0                  0                 0                     1  \n",
       "1                  0                 0                     0  \n",
       "2                  0                 0                     0  \n",
       "3                  0                 0                     1  \n",
       "4                  0                 0                     0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos training y testing dataset (previamente preparados)\n",
    "df_test = pd.read_csv(\"testingDF.csv\")\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>InCabin</th>\n",
       "      <th>Room</th>\n",
       "      <th>Title</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Fare_Per_Person</th>\n",
       "      <th>...</th>\n",
       "      <th>Deck_N</th>\n",
       "      <th>Deck_T</th>\n",
       "      <th>AgeGroup_Adult</th>\n",
       "      <th>AgeGroup_Baby</th>\n",
       "      <th>AgeGroup_Child</th>\n",
       "      <th>AgeGroup_Senior</th>\n",
       "      <th>AgeGroup_Student</th>\n",
       "      <th>AgeGroup_Teenager</th>\n",
       "      <th>AgeGroup_Unknown</th>\n",
       "      <th>AgeGroup_Young Adult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8419</td>\n",
       "      <td>0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.6862</td>\n",
       "      <td>0.4547</td>\n",
       "      <td>-1.0388</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.5461</td>\n",
       "      <td>1</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.2175</td>\n",
       "      <td>-0.9323</td>\n",
       "      <td>-0.2725</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8419</td>\n",
       "      <td>1</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>-0.5583</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.9323</td>\n",
       "      <td>0.7664</td>\n",
       "      <td>-0.1439</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.5461</td>\n",
       "      <td>1</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.5990</td>\n",
       "      <td>-0.9323</td>\n",
       "      <td>-0.3504</td>\n",
       "      <td>0.3959</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8419</td>\n",
       "      <td>0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>-0.5583</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.6862</td>\n",
       "      <td>1.4676</td>\n",
       "      <td>-0.1279</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex      Fare  FamilySize  IsAlone  InCabin    Room   Title  \\\n",
       "0  0.8419    0  2.110213      0.0734        0    False -0.0000  0.6862   \n",
       "1 -1.5461    1  4.280593      0.0734        0     True  2.2175 -0.9323   \n",
       "2  0.8419    1  2.188856     -0.5583        1    False -0.0000 -0.9323   \n",
       "3 -1.5461    1  3.990834      0.0734        0     True  4.5990 -0.9323   \n",
       "4  0.8419    0  2.202765     -0.5583        1    False -0.0000  0.6862   \n",
       "\n",
       "   Age*Class  Fare_Per_Person  ...  Deck_N  Deck_T  AgeGroup_Adult  \\\n",
       "0     0.4547          -1.0388  ...       1       0               0   \n",
       "1    -0.2725           0.6170  ...       0       0               1   \n",
       "2     0.7664          -0.1439  ...       1       0               0   \n",
       "3    -0.3504           0.3959  ...       0       0               0   \n",
       "4     1.4676          -0.1279  ...       1       0               0   \n",
       "\n",
       "   AgeGroup_Baby  AgeGroup_Child  AgeGroup_Senior  AgeGroup_Student  \\\n",
       "0              0               0                0                 1   \n",
       "1              0               0                0                 0   \n",
       "2              0               0                0                 0   \n",
       "3              0               0                0                 0   \n",
       "4              0               0                0                 0   \n",
       "\n",
       "   AgeGroup_Teenager  AgeGroup_Unknown  AgeGroup_Young Adult  \n",
       "0                  0                 0                     0  \n",
       "1                  0                 0                     0  \n",
       "2                  0                 0                     1  \n",
       "3                  0                 0                     1  \n",
       "4                  0                 0                     1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"trainDF.csv\")\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se importa el train.csv solo para extraer la variable dep. Survived\n",
    "y = pd.read_csv(\"train.csv\")\n",
    "y_train = y['Survived']\n",
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    892\n",
       "1    893\n",
       "2    894\n",
       "3    895\n",
       "4    896\n",
       "Name: PassengerId, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# guardamos las IDS de los pasajeros de testing para la submission con las predicciones\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "ids = test['PassengerId']\n",
    "ids.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para poder validar correctamente el modelo aplicamos un 80/20 a mi fichero de training\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y_train, \n",
    "                                                    test_size=0.20,\n",
    "                                                   random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para validar los parámetros del modelo realizamos un split validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                 test_size=0.20,\n",
    "                                                 random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 35)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 35)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    3.8s remaining:    8.8s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    1.3s remaining:    3.0s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    0.9s remaining:    2.0s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    1.0s remaining:    2.2s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    0.6s remaining:    1.4s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    2.0s remaining:    4.7s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    3.7s finished\n"
     ]
    }
   ],
   "source": [
    "## PARTE 2 n_jobs = 10 // n_splits=10\n",
    "# Realizamos la iteración Cross Validation con Kfold\n",
    "K_fold = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# modelado con un estado random\n",
    "random_state = 17\n",
    "\n",
    "# Pasos para generar de forma conjunta un k-fold para diferentes estimadores\n",
    "models = []\n",
    "cv_results = []\n",
    "cv_means = []\n",
    "cv_std = []\n",
    "\n",
    "# Parte II\n",
    "# generamos los modelos con los estimadores confjgurando los valores por defecto\n",
    "models.append(KNeighborsClassifier())\n",
    "models.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state), random_state=random_state, learning_rate=0.1))\n",
    "models.append(DecisionTreeClassifier(random_state=random_state))\n",
    "models.append(RandomForestClassifier(random_state=random_state))\n",
    "models.append(ExtraTreesClassifier(random_state=random_state))\n",
    "models.append(SVC(random_state=random_state))\n",
    "models.append(GradientBoostingClassifier(random_state=random_state))\n",
    "models.append(LogisticRegression(random_state=random_state))\n",
    "models.append(LinearDiscriminantAnalysis())\n",
    "models.append(MLPClassifier(random_state=random_state))\n",
    "\n",
    "\n",
    "# Realizamos una iteración con el cross_val\n",
    "for model in models:\n",
    "    cv_results.append(cross_val_score(model, X_train, y_train,\n",
    "                                     scoring='accuracy',\n",
    "                                     cv = K_fold,\n",
    "                                     n_jobs = 10,\n",
    "                                     verbose = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteramos los resultados del cross-validation (mean y std)\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe con los valores almacenados\n",
    "cv_frame = pd.DataFrame(\n",
    "    {\n",
    "        \"CrossValMeans\": cv_means,\n",
    "        \"CrossValErros\": cv_std,\n",
    "        \"Algorithms\":[\n",
    "            \"KNeighboors\",\n",
    "            \"AdaBoost\",\n",
    "            \"DecisionTree\",\n",
    "            \"RandomForest\",\n",
    "            \"ExtraTrees\",\n",
    "            \"SVC\",\n",
    "            \"GradientBoosting\",\n",
    "            \"LogisticRegression\",\n",
    "            \"LinearDiscriminantAnalysis\",\n",
    "            \"MultipleLayerPerceptron\"\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Representamos estos valores del dataframe en un gráfico de barras\n",
    "cv_plot = sns.barplot(\"CrossValMeans\", \"Algorithms\", data = cv_frame,\n",
    "                     palette=\"husl\", orient='h', **{'xerr':cv_std})\n",
    "cv_plot.set_xlabel(\"Mean Accuracy\")\n",
    "cv_plot = cv_plot.set_title(\"CV Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 5.2.2 - Realizamos la tarea de micro-ajuste a los parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "`Random Forest`\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random%20forest#sklearn.ensemble.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier kfol=10\n",
    "RF_Model= RandomForestClassifier()\n",
    "\n",
    "RF_scores = cross_val_score(RF_Model, X_train, y_train, cv = K_fold,\n",
    "                       n_jobs = 4, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89473684 0.84210526 0.73684211 0.80701754 0.85964912 0.77192982\n",
      " 0.77192982 0.85964912 0.8245614  0.78571429]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.54"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos los resultados en pantalla\n",
    "print(RF_scores)\n",
    "round(np.mean(RF_scores)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   17.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier kfol=20\n",
    "cv = 20\n",
    "RF_Model= RandomForestClassifier()\n",
    "\n",
    "RF_scores_20 = cross_val_score(RF_Model, X_train, y_train, cv = cv,\n",
    "                       n_jobs = 4, scoring = 'accuracy', verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.66666667 1.         0.66666667 0.83333333\n",
      " 0.83333333 1.         0.83333333 1.         1.         0.66666667\n",
      " 0.83333333 0.83333333 0.66666667 1.         0.33333333 1.\n",
      " 0.5        0.5        0.83333333 1.         0.83333333 1.\n",
      " 0.83333333 0.66666667 0.83333333 0.66666667 0.83333333 0.66666667\n",
      " 1.         0.83333333 0.66666667 0.83333333 0.83333333 1.\n",
      " 0.83333333 0.66666667 0.5        0.83333333 0.66666667 1.\n",
      " 1.         1.         0.5        0.66666667 0.5        1.\n",
      " 0.83333333 0.83333333 1.         0.83333333 1.         0.83333333\n",
      " 0.66666667 0.83333333 1.         0.66666667 0.83333333 0.83333333\n",
      " 0.66666667 0.83333333 0.83333333 0.83333333 0.5        0.66666667\n",
      " 0.83333333 0.83333333 0.66666667 0.6        1.         0.6\n",
      " 0.8        1.         1.         0.8        1.         0.8\n",
      " 0.6        0.8        0.8        0.8        0.6        0.8\n",
      " 0.8        1.         0.8        1.         1.         0.8\n",
      " 1.         0.8        0.8        0.8        1.         0.6\n",
      " 0.6        1.         0.8        0.8       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos los resultados en pantalla\n",
    "print(RF_scores_20)\n",
    "round(np.mean(RF_scores_20)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 192 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 400\n",
      "building tree 2 of 400\n",
      "building tree 3 of 400\n",
      "building tree 4 of 400\n",
      "building tree 5 of 400\n",
      "building tree 6 of 400\n",
      "building tree 7 of 400\n",
      "building tree 8 of 400\n",
      "building tree 9 of 400\n",
      "building tree 10 of 400\n",
      "building tree 11 of 400\n",
      "building tree 12 of 400\n",
      "building tree 13 of 400\n",
      "building tree 14 of 400\n",
      "building tree 15 of 400\n",
      "building tree 16 of 400\n",
      "building tree 17 of 400\n",
      "building tree 18 of 400\n",
      "building tree 19 of 400\n",
      "building tree 20 of 400\n",
      "building tree 21 of 400\n",
      "building tree 22 of 400\n",
      "building tree 23 of 400\n",
      "building tree 24 of 400\n",
      "building tree 25 of 400\n",
      "building tree 26 of 400\n",
      "building tree 27 of 400\n",
      "building tree 28 of 400\n",
      "building tree 29 of 400\n",
      "building tree 30 of 400\n",
      "building tree 31 of 400\n",
      "building tree 32 of 400\n",
      "building tree 33 of 400\n",
      "building tree 34 of 400\n",
      "building tree 35 of 400\n",
      "building tree 36 of 400\n",
      "building tree 37 of 400\n",
      "building tree 38 of 400\n",
      "building tree 39 of 400\n",
      "building tree 40 of 400\n",
      "building tree 41 of 400\n",
      "building tree 42 of 400\n",
      "building tree 43 of 400\n",
      "building tree 44 of 400\n",
      "building tree 45 of 400\n",
      "building tree 46 of 400\n",
      "building tree 47 of 400\n",
      "building tree 48 of 400\n",
      "building tree 49 of 400\n",
      "building tree 50 of 400\n",
      "building tree 51 of 400\n",
      "building tree 52 of 400\n",
      "building tree 53 of 400\n",
      "building tree 54 of 400\n",
      "building tree 55 of 400\n",
      "building tree 56 of 400\n",
      "building tree 57 of 400\n",
      "building tree 58 of 400\n",
      "building tree 59 of 400\n",
      "building tree 60 of 400\n",
      "building tree 61 of 400\n",
      "building tree 62 of 400\n",
      "building tree 63 of 400\n",
      "building tree 64 of 400\n",
      "building tree 65 of 400\n",
      "building tree 66 of 400\n",
      "building tree 67 of 400\n",
      "building tree 68 of 400\n",
      "building tree 69 of 400\n",
      "building tree 70 of 400\n",
      "building tree 71 of 400\n",
      "building tree 72 of 400\n",
      "building tree 73 of 400\n",
      "building tree 74 of 400\n",
      "building tree 75 of 400\n",
      "building tree 76 of 400\n",
      "building tree 77 of 400\n",
      "building tree 78 of 400\n",
      "building tree 79 of 400\n",
      "building tree 80 of 400\n",
      "building tree 81 of 400\n",
      "building tree 82 of 400\n",
      "building tree 83 of 400\n",
      "building tree 84 of 400\n",
      "building tree 85 of 400\n",
      "building tree 86 of 400\n",
      "building tree 87 of 400\n",
      "building tree 88 of 400\n",
      "building tree 89 of 400\n",
      "building tree 90 of 400\n",
      "building tree 91 of 400\n",
      "building tree 92 of 400\n",
      "building tree 93 of 400\n",
      "building tree 94 of 400\n",
      "building tree 95 of 400\n",
      "building tree 96 of 400\n",
      "building tree 97 of 400\n",
      "building tree 98 of 400\n",
      "building tree 99 of 400\n",
      "building tree 100 of 400\n",
      "building tree 101 of 400\n",
      "building tree 102 of 400\n",
      "building tree 103 of 400\n",
      "building tree 104 of 400\n",
      "building tree 105 of 400\n",
      "building tree 106 of 400\n",
      "building tree 107 of 400\n",
      "building tree 108 of 400\n",
      "building tree 109 of 400\n",
      "building tree 110 of 400\n",
      "building tree 111 of 400\n",
      "building tree 112 of 400\n",
      "building tree 113 of 400\n",
      "building tree 114 of 400\n",
      "building tree 115 of 400\n",
      "building tree 116 of 400\n",
      "building tree 117 of 400\n",
      "building tree 118 of 400\n",
      "building tree 119 of 400\n",
      "building tree 120 of 400\n",
      "building tree 121 of 400\n",
      "building tree 122 of 400\n",
      "building tree 123 of 400\n",
      "building tree 124 of 400\n",
      "building tree 125 of 400\n",
      "building tree 126 of 400\n",
      "building tree 127 of 400\n",
      "building tree 128 of 400\n",
      "building tree 129 of 400\n",
      "building tree 130 of 400\n",
      "building tree 131 of 400\n",
      "building tree 132 of 400\n",
      "building tree 133 of 400\n",
      "building tree 134 of 400\n",
      "building tree 135 of 400\n",
      "building tree 136 of 400\n",
      "building tree 137 of 400\n",
      "building tree 138 of 400\n",
      "building tree 139 of 400\n",
      "building tree 140 of 400\n",
      "building tree 141 of 400\n",
      "building tree 142 of 400\n",
      "building tree 143 of 400\n",
      "building tree 144 of 400\n",
      "building tree 145 of 400\n",
      "building tree 146 of 400\n",
      "building tree 147 of 400\n",
      "building tree 148 of 400\n",
      "building tree 149 of 400\n",
      "building tree 150 of 400\n",
      "building tree 151 of 400\n",
      "building tree 152 of 400\n",
      "building tree 153 of 400\n",
      "building tree 154 of 400\n",
      "building tree 155 of 400\n",
      "building tree 156 of 400\n",
      "building tree 157 of 400\n",
      "building tree 158 of 400\n",
      "building tree 159 of 400\n",
      "building tree 160 of 400\n",
      "building tree 161 of 400\n",
      "building tree 162 of 400\n",
      "building tree 163 of 400\n",
      "building tree 164 of 400\n",
      "building tree 165 of 400\n",
      "building tree 166 of 400\n",
      "building tree 167 of 400\n",
      "building tree 168 of 400\n",
      "building tree 169 of 400\n",
      "building tree 170 of 400\n",
      "building tree 171 of 400\n",
      "building tree 172 of 400\n",
      "building tree 173 of 400\n",
      "building tree 174 of 400\n",
      "building tree 175 of 400\n",
      "building tree 176 of 400\n",
      "building tree 177 of 400\n",
      "building tree 178 of 400\n",
      "building tree 179 of 400\n",
      "building tree 180 of 400\n",
      "building tree 181 of 400\n",
      "building tree 182 of 400\n",
      "building tree 183 of 400\n",
      "building tree 184 of 400\n",
      "building tree 185 of 400\n",
      "building tree 186 of 400\n",
      "building tree 187 of 400\n",
      "building tree 188 of 400\n",
      "building tree 189 of 400\n",
      "building tree 190 of 400\n",
      "building tree 191 of 400\n",
      "building tree 192 of 400\n",
      "building tree 193 of 400\n",
      "building tree 194 of 400\n",
      "building tree 195 of 400\n",
      "building tree 196 of 400\n",
      "building tree 197 of 400\n",
      "building tree 198 of 400\n",
      "building tree 199 of 400\n",
      "building tree 200 of 400\n",
      "building tree 201 of 400\n",
      "building tree 202 of 400\n",
      "building tree 203 of 400\n",
      "building tree 204 of 400\n",
      "building tree 205 of 400\n",
      "building tree 206 of 400\n",
      "building tree 207 of 400\n",
      "building tree 208 of 400\n",
      "building tree 209 of 400\n",
      "building tree 210 of 400\n",
      "building tree 211 of 400\n",
      "building tree 212 of 400\n",
      "building tree 213 of 400\n",
      "building tree 214 of 400\n",
      "building tree 215 of 400\n",
      "building tree 216 of 400\n",
      "building tree 217 of 400\n",
      "building tree 218 of 400\n",
      "building tree 219 of 400\n",
      "building tree 220 of 400\n",
      "building tree 221 of 400\n",
      "building tree 222 of 400\n",
      "building tree 223 of 400\n",
      "building tree 224 of 400\n",
      "building tree 225 of 400\n",
      "building tree 226 of 400\n",
      "building tree 227 of 400\n",
      "building tree 228 of 400\n",
      "building tree 229 of 400\n",
      "building tree 230 of 400\n",
      "building tree 231 of 400\n",
      "building tree 232 of 400\n",
      "building tree 233 of 400\n",
      "building tree 234 of 400\n",
      "building tree 235 of 400\n",
      "building tree 236 of 400\n",
      "building tree 237 of 400\n",
      "building tree 238 of 400\n",
      "building tree 239 of 400\n",
      "building tree 240 of 400\n",
      "building tree 241 of 400\n",
      "building tree 242 of 400\n",
      "building tree 243 of 400\n",
      "building tree 244 of 400\n",
      "building tree 245 of 400\n",
      "building tree 246 of 400\n",
      "building tree 247 of 400\n",
      "building tree 248 of 400\n",
      "building tree 249 of 400\n",
      "building tree 250 of 400\n",
      "building tree 251 of 400\n",
      "building tree 252 of 400\n",
      "building tree 253 of 400\n",
      "building tree 254 of 400\n",
      "building tree 255 of 400\n",
      "building tree 256 of 400\n",
      "building tree 257 of 400\n",
      "building tree 258 of 400\n",
      "building tree 259 of 400\n",
      "building tree 260 of 400\n",
      "building tree 261 of 400\n",
      "building tree 262 of 400\n",
      "building tree 263 of 400\n",
      "building tree 264 of 400\n",
      "building tree 265 of 400\n",
      "building tree 266 of 400\n",
      "building tree 267 of 400\n",
      "building tree 268 of 400\n",
      "building tree 269 of 400\n",
      "building tree 270 of 400\n",
      "building tree 271 of 400\n",
      "building tree 272 of 400\n",
      "building tree 273 of 400\n",
      "building tree 274 of 400\n",
      "building tree 275 of 400\n",
      "building tree 276 of 400\n",
      "building tree 277 of 400\n",
      "building tree 278 of 400\n",
      "building tree 279 of 400\n",
      "building tree 280 of 400\n",
      "building tree 281 of 400\n",
      "building tree 282 of 400\n",
      "building tree 283 of 400\n",
      "building tree 284 of 400\n",
      "building tree 285 of 400\n",
      "building tree 286 of 400\n",
      "building tree 287 of 400\n",
      "building tree 288 of 400\n",
      "building tree 289 of 400\n",
      "building tree 290 of 400\n",
      "building tree 291 of 400\n",
      "building tree 292 of 400\n",
      "building tree 293 of 400\n",
      "building tree 294 of 400\n",
      "building tree 295 of 400\n",
      "building tree 296 of 400\n",
      "building tree 297 of 400\n",
      "building tree 298 of 400\n",
      "building tree 299 of 400\n",
      "building tree 300 of 400\n",
      "building tree 301 of 400\n",
      "building tree 302 of 400\n",
      "building tree 303 of 400\n",
      "building tree 304 of 400\n",
      "building tree 305 of 400\n",
      "building tree 306 of 400\n",
      "building tree 307 of 400\n",
      "building tree 308 of 400\n",
      "building tree 309 of 400\n",
      "building tree 310 of 400\n",
      "building tree 311 of 400\n",
      "building tree 312 of 400\n",
      "building tree 313 of 400\n",
      "building tree 314 of 400\n",
      "building tree 315 of 400\n",
      "building tree 316 of 400\n",
      "building tree 317 of 400\n",
      "building tree 318 of 400\n",
      "building tree 319 of 400\n",
      "building tree 320 of 400\n",
      "building tree 321 of 400\n",
      "building tree 322 of 400\n",
      "building tree 323 of 400\n",
      "building tree 324 of 400\n",
      "building tree 325 of 400\n",
      "building tree 326 of 400\n",
      "building tree 327 of 400\n",
      "building tree 328 of 400\n",
      "building tree 329 of 400\n",
      "building tree 330 of 400\n",
      "building tree 331 of 400\n",
      "building tree 332 of 400\n",
      "building tree 333 of 400\n",
      "building tree 334 of 400\n",
      "building tree 335 of 400\n",
      "building tree 336 of 400\n",
      "building tree 337 of 400\n",
      "building tree 338 of 400\n",
      "building tree 339 of 400\n",
      "building tree 340 of 400\n",
      "building tree 341 of 400\n",
      "building tree 342 of 400\n",
      "building tree 343 of 400\n",
      "building tree 344 of 400\n",
      "building tree 345 of 400\n",
      "building tree 346 of 400\n",
      "building tree 347 of 400\n",
      "building tree 348 of 400\n",
      "building tree 349 of 400\n",
      "building tree 350 of 400\n",
      "building tree 351 of 400\n",
      "building tree 352 of 400\n",
      "building tree 353 of 400\n",
      "building tree 354 of 400\n",
      "building tree 355 of 400\n",
      "building tree 356 of 400\n",
      "building tree 357 of 400\n",
      "building tree 358 of 400\n",
      "building tree 359 of 400\n",
      "building tree 360 of 400\n",
      "building tree 361 of 400\n",
      "building tree 362 of 400\n",
      "building tree 363 of 400\n",
      "building tree 364 of 400\n",
      "building tree 365 of 400\n",
      "building tree 366 of 400\n",
      "building tree 367 of 400\n",
      "building tree 368 of 400\n",
      "building tree 369 of 400\n",
      "building tree 370 of 400\n",
      "building tree 371 of 400\n",
      "building tree 372 of 400\n",
      "building tree 373 of 400\n",
      "building tree 374 of 400\n",
      "building tree 375 of 400\n",
      "building tree 376 of 400\n",
      "building tree 377 of 400\n",
      "building tree 378 of 400\n",
      "building tree 379 of 400\n",
      "building tree 380 of 400\n",
      "building tree 381 of 400\n",
      "building tree 382 of 400\n",
      "building tree 383 of 400\n",
      "building tree 384 of 400\n",
      "building tree 385 of 400\n",
      "building tree 386 of 400\n",
      "building tree 387 of 400\n",
      "building tree 388 of 400\n",
      "building tree 389 of 400\n",
      "building tree 390 of 400\n",
      "building tree 391 of 400\n",
      "building tree 392 of 400\n",
      "building tree 393 of 400\n",
      "building tree 394 of 400\n",
      "building tree 395 of 400\n",
      "building tree 396 of 400\n",
      "building tree 397 of 400\n",
      "building tree 398 of 400\n",
      "building tree 399 of 400\n",
      "building tree 400 of 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8417919799498745"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizamos el tuneado de los parámetros del estimador RF\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "# Creamos una tarea de tuneado basado en grid\n",
    "rf_param_grid = {\n",
    "    # Creamos un grid con los parámetros a iterar, para ello necesitaremos realizar iteración de n valores por parámetros\n",
    "              \"n_estimators\": [100, 200, 300, 400],\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "            \"max_depth\" : [None], # por defecto hasta la máxima profundidad necesaria para quitar las impurezas\n",
    "            \"min_samples_split\" : [2, 6, 20],\n",
    "           \"min_samples_leaf\" : [1, 4, 16, 32],\n",
    "            \"max_features\": [\"auto\", \"log2\"] ,\n",
    "            \"max_leaf_nodes\" : [None] , # por defecto indica que es ilimitado\n",
    "             \"random_state\" : [17],\n",
    "            \"verbose\" : [2]\n",
    "}\n",
    "\n",
    "\n",
    "# Construimos nuestro modelo con estos parámetros con K-fold = 10\n",
    "gsRF = GridSearchCV(RF, param_grid=rf_param_grid, cv=10,\n",
    "                    scoring='accuracy', n_jobs=4, verbose=2)\n",
    "\n",
    "# Aplicamos el ajuste\n",
    "gsRF.fit(X_train, y_train)\n",
    "\n",
    "# Extraemos el mejor estimador\n",
    "RF_best = gsRF.best_estimator_\n",
    "\n",
    "# Extraemos el mejor resultado\n",
    "gsRF.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 400,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 17,\n",
       " 'verbose': 2,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos los mejores parámetro para este modelo\n",
    "RF_best.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.7371634 , 1.76088784, 3.03276408, 3.23405762, 0.75001295,\n",
       "        1.51317859, 2.26997361, 3.07647955, 0.59678071, 1.14963062,\n",
       "        1.7480958 , 3.19420941, 0.62517765, 1.12527337, 1.72069936,\n",
       "        2.28445539, 0.57560203, 1.14821417, 1.67869358, 3.05127742,\n",
       "        1.06284916, 1.17959213, 1.80816185, 2.1716572 , 0.53886456,\n",
       "        2.24048367, 2.63123422, 3.55905769, 0.5922395 , 1.08676937,\n",
       "        2.00352194, 2.75186892, 0.55620711, 1.1239219 , 2.52814209,\n",
       "        2.86273551, 1.09792912, 2.36460881, 2.0516964 , 2.26883373,\n",
       "        0.67159221, 1.10918939, 1.64297736, 2.83328977, 0.70575902,\n",
       "        2.24784706, 2.42026696, 2.57195108, 0.61581311, 1.34243617,\n",
       "        2.06428616, 3.1418092 , 1.12764871, 2.83757753, 2.71261499,\n",
       "        4.01423998, 0.99921968, 1.99780416, 2.60436747, 3.5447186 ,\n",
       "        0.76549294, 1.55387814, 2.83934624, 2.58785512, 0.69527912,\n",
       "        1.74915953, 2.17399077, 3.14954295, 0.65375912, 1.16097648,\n",
       "        1.87964447, 2.54144917, 0.61620979, 1.15221667, 1.99597137,\n",
       "        3.22268417, 0.9778249 , 1.65238974, 2.04116361, 2.75034313,\n",
       "        0.74271626, 1.28061304, 1.93561957, 5.85289869, 1.97079015,\n",
       "        2.9037498 , 1.88654494, 2.29398141, 0.6189955 , 1.52588325,\n",
       "        1.86238561, 3.12254605, 0.70787373, 1.69769866, 1.85060456,\n",
       "        3.17571385, 1.12247024, 1.32328868, 1.94332268, 2.91559935,\n",
       "        0.79272802, 1.27523029, 2.08259261, 2.63298857, 0.6079031 ,\n",
       "        1.51356518, 1.96209519, 3.07091467, 1.00997193, 2.07034745,\n",
       "        2.78075471, 2.66765132, 0.64477513, 1.42369199, 2.96305468,\n",
       "        2.57265577, 0.63806252, 1.20672784, 2.21464202, 3.01830525,\n",
       "        0.55731983, 1.15662742, 2.68830762, 4.19514887, 1.00134194,\n",
       "        1.41462655, 2.6613801 , 6.08328867, 1.62353168, 4.27646701,\n",
       "        6.35237381, 5.8985728 , 0.72217979, 1.65836446, 2.08223748,\n",
       "        3.14498169, 0.59472735, 1.66755092, 2.73700438, 2.88547962,\n",
       "        0.7095871 , 1.31853724, 2.12015269, 2.50580311, 0.69791415,\n",
       "        1.49464395, 2.49696364, 3.6645695 , 0.60619473, 1.69207656,\n",
       "        1.96112511, 2.70448065, 0.87240922, 1.42749012, 2.75970948,\n",
       "        2.63029342, 0.66593611, 1.26328042, 1.82606833, 2.43075111,\n",
       "        0.63627725, 1.24614041, 2.32727695, 2.42730165, 0.61250391,\n",
       "        1.20938356, 2.01017561, 2.86388338, 0.63441384, 1.15372488,\n",
       "        1.8269654 , 3.02979114, 0.73875928, 1.32270916, 1.89916992,\n",
       "        2.78428533, 0.74796021, 1.24878619, 1.91309133, 2.24013646,\n",
       "        0.58224509, 1.08428445, 1.95847299, 2.76171153, 0.82546799,\n",
       "        1.48189595, 1.95168116, 2.70920165, 0.64773953, 1.30125504,\n",
       "        1.68411126, 2.29286983]),\n",
       " 'std_fit_time': array([0.11689854, 0.71248547, 1.281164  , 0.88901736, 0.24141311,\n",
       "        0.29184925, 0.60943023, 0.79255875, 0.01332135, 0.01705706,\n",
       "        0.03753387, 0.96761049, 0.05855233, 0.12133765, 0.08308028,\n",
       "        0.02773515, 0.01772286, 0.02548445, 0.0207127 , 0.90311673,\n",
       "        0.2582018 , 0.09024989, 0.18322301, 0.02699958, 0.01308328,\n",
       "        0.48091127, 0.57665979, 0.41455535, 0.02485443, 0.01680685,\n",
       "        0.42648655, 0.35449307, 0.0175592 , 0.06025384, 0.62311933,\n",
       "        0.34483844, 0.09842253, 0.30677179, 0.38790974, 0.23465703,\n",
       "        0.14833014, 0.14780344, 0.0582307 , 0.20622007, 0.1247317 ,\n",
       "        0.5000803 , 0.56337528, 0.16988988, 0.03669709, 0.08469144,\n",
       "        0.12512157, 0.51649478, 0.25644631, 1.17090657, 0.115481  ,\n",
       "        0.41487187, 0.12093005, 0.10241018, 0.23361413, 0.22944695,\n",
       "        0.06438663, 0.19829491, 0.54598937, 0.28189904, 0.13908652,\n",
       "        0.32899551, 0.27201625, 0.31845939, 0.06825006, 0.01777173,\n",
       "        0.16868217, 0.13553124, 0.04682498, 0.03257403, 0.31728491,\n",
       "        0.14521912, 0.18133326, 0.28186006, 0.26825388, 0.28563356,\n",
       "        0.15387318, 0.08846795, 0.50556796, 2.12584383, 0.45369671,\n",
       "        0.88842139, 0.19731657, 0.09136802, 0.04201957, 0.16936718,\n",
       "        0.16693422, 0.28654255, 0.10789255, 0.38804895, 0.06313328,\n",
       "        0.69587048, 0.1432105 , 0.20162582, 0.05310181, 0.23216817,\n",
       "        0.08164012, 0.03085293, 0.123629  , 0.09796803, 0.03320051,\n",
       "        0.27396023, 0.2003961 , 0.41405243, 0.25397464, 0.62943234,\n",
       "        0.29016489, 0.44177447, 0.03751157, 0.39499955, 1.16054929,\n",
       "        0.22698161, 0.04079068, 0.04721388, 0.42813436, 0.51630965,\n",
       "        0.0271197 , 0.11530658, 0.25897223, 0.33418215, 0.15436323,\n",
       "        0.07166983, 0.5370143 , 1.29017425, 0.36951994, 1.44209192,\n",
       "        1.79939093, 1.69108781, 0.11621151, 0.17609288, 0.33010477,\n",
       "        0.18102262, 0.01270202, 0.46202793, 0.23726982, 0.25687404,\n",
       "        0.10473692, 0.11545296, 0.15468289, 0.1816641 , 0.03239191,\n",
       "        0.31961231, 0.25597659, 0.39976216, 0.02786672, 0.21829424,\n",
       "        0.07478339, 0.26568499, 0.1718493 , 0.16953536, 0.47392885,\n",
       "        0.11956689, 0.02238471, 0.0760712 , 0.06864579, 0.0598731 ,\n",
       "        0.0279902 , 0.01501113, 0.36477987, 0.02698708, 0.03245952,\n",
       "        0.02495363, 0.20481694, 0.30700838, 0.03368633, 0.033055  ,\n",
       "        0.05222604, 0.06339893, 0.09214614, 0.17026524, 0.20201068,\n",
       "        0.29481123, 0.03268745, 0.07754475, 0.19952339, 0.04963966,\n",
       "        0.02311474, 0.02793332, 0.27771965, 0.55628599, 0.10866113,\n",
       "        0.24325212, 0.23523403, 0.17511671, 0.07810107, 0.10700373,\n",
       "        0.0350366 , 0.13197776]),\n",
       " 'mean_score_time': array([0.04562471, 0.14436483, 0.11963687, 0.24267852, 0.06332049,\n",
       "        0.10206339, 0.19053261, 0.16244822, 0.04868028, 0.07900867,\n",
       "        0.10644155, 0.20741198, 0.05051296, 0.07632194, 0.10325673,\n",
       "        0.14191499, 0.0448319 , 0.07321978, 0.10510538, 0.28906567,\n",
       "        0.07146666, 0.07448511, 0.10279937, 0.13760526, 0.03874876,\n",
       "        0.23354814, 0.24711361, 0.25352657, 0.04473693, 0.07464263,\n",
       "        0.14590583, 0.15807071, 0.04359391, 0.07618656, 0.18335049,\n",
       "        0.16670949, 0.08081102, 0.17150564, 0.11809187, 0.14273088,\n",
       "        0.0596827 , 0.05776792, 0.11834097, 0.18970864, 0.05549245,\n",
       "        0.20226562, 0.14158602, 0.14868081, 0.04238153, 0.08750148,\n",
       "        0.1183347 , 0.2327786 , 0.10259402, 0.11651697, 0.17661471,\n",
       "        0.24592037, 0.08195264, 0.14229245, 0.15514326, 0.21680107,\n",
       "        0.0516701 , 0.09813154, 0.22799783, 0.15579958, 0.05393293,\n",
       "        0.12921453, 0.15190916, 0.20164342, 0.05420337, 0.07358809,\n",
       "        0.13793037, 0.14363327, 0.05182493, 0.07497528, 0.1446321 ,\n",
       "        0.21628883, 0.073297  , 0.08359118, 0.12984605, 0.14872067,\n",
       "        0.05260305, 0.08867111, 0.21386549, 0.45922301, 0.16952941,\n",
       "        0.15968459, 0.11180203, 0.15168147, 0.04538872, 0.12292302,\n",
       "        0.12547901, 0.19382136, 0.06271787, 0.15173559, 0.11752024,\n",
       "        0.25816953, 0.07784479, 0.07597356, 0.11801956, 0.19047461,\n",
       "        0.0432225 , 0.07600021, 0.11062303, 0.15039921, 0.04246624,\n",
       "        0.1023273 , 0.14545169, 0.18227408, 0.07381992, 0.09173565,\n",
       "        0.17059608, 0.14907577, 0.04925194, 0.13062615, 0.14674482,\n",
       "        0.1384407 , 0.04327781, 0.07214513, 0.14692385, 0.16472344,\n",
       "        0.04422619, 0.08433645, 0.14809716, 0.2229763 , 0.06733451,\n",
       "        0.09681282, 0.21297796, 0.38019464, 0.1141758 , 0.19634163,\n",
       "        0.40469606, 0.28467972, 0.05480778, 0.11532876, 0.1190382 ,\n",
       "        0.16695337, 0.04220591, 0.13413389, 0.17924402, 0.21142557,\n",
       "        0.05870941, 0.07714949, 0.13338845, 0.17745109, 0.04637718,\n",
       "        0.09495356, 0.21141052, 0.21948142, 0.04160731, 0.10604768,\n",
       "        0.11406615, 0.17668321, 0.06302841, 0.09590738, 0.15565689,\n",
       "        0.15688846, 0.04533808, 0.081706  , 0.11742392, 0.1476562 ,\n",
       "        0.0429934 , 0.07922277, 0.13930116, 0.14913135, 0.04439504,\n",
       "        0.07627859, 0.12080882, 0.14989338, 0.04229736, 0.07619116,\n",
       "        0.12122004, 0.19024687, 0.05234506, 0.09120097, 0.12252145,\n",
       "        0.17790983, 0.05418274, 0.08253093, 0.11462207, 0.14229937,\n",
       "        0.04268682, 0.07212279, 0.13200347, 0.20378802, 0.06887751,\n",
       "        0.08272305, 0.13024154, 0.14643738, 0.04820502, 0.0861151 ,\n",
       "        0.12372446, 0.13386734]),\n",
       " 'std_score_time': array([0.00724706, 0.09822537, 0.03859568, 0.14451848, 0.03548267,\n",
       "        0.04644057, 0.06857141, 0.05322732, 0.00631219, 0.00684497,\n",
       "        0.00959993, 0.11843452, 0.01875148, 0.00922799, 0.01072659,\n",
       "        0.00934396, 0.00818014, 0.00718567, 0.00985952, 0.18044276,\n",
       "        0.03143084, 0.00567866, 0.0052922 , 0.01203159, 0.00578912,\n",
       "        0.12148507, 0.11599339, 0.08613253, 0.00460616, 0.00878058,\n",
       "        0.04060894, 0.04269527, 0.00660581, 0.0088873 , 0.07544176,\n",
       "        0.03907806, 0.04292028, 0.09361168, 0.0209655 , 0.05586822,\n",
       "        0.01906701, 0.01205036, 0.02327362, 0.05472779, 0.01444683,\n",
       "        0.08063134, 0.04168529, 0.02832934, 0.00903963, 0.01686491,\n",
       "        0.01355256, 0.09876353, 0.04566544, 0.00679766, 0.05647756,\n",
       "        0.04962086, 0.01496868, 0.0165102 , 0.02290267, 0.04307527,\n",
       "        0.0039941 , 0.01398085, 0.14737564, 0.01851202, 0.01517373,\n",
       "        0.06352082, 0.07522733, 0.09126632, 0.03265469, 0.00705879,\n",
       "        0.06133829, 0.01670258, 0.01175151, 0.00915556, 0.04689286,\n",
       "        0.06201239, 0.02930866, 0.02644327, 0.04411554, 0.01556946,\n",
       "        0.01896763, 0.02923525, 0.20532619, 0.27257808, 0.05149698,\n",
       "        0.04993079, 0.00751025, 0.01759415, 0.01098044, 0.05373848,\n",
       "        0.02412287, 0.04469197, 0.02418073, 0.06414308, 0.01550719,\n",
       "        0.11390724, 0.02574249, 0.0137892 , 0.01025348, 0.09956418,\n",
       "        0.01176741, 0.00633426, 0.00878457, 0.02224943, 0.00602502,\n",
       "        0.02565747, 0.07829873, 0.06515676, 0.04275347, 0.02597371,\n",
       "        0.06510263, 0.03850177, 0.00947382, 0.10529934, 0.05948777,\n",
       "        0.01018479, 0.00542126, 0.00463104, 0.04111429, 0.05446182,\n",
       "        0.00674124, 0.0264311 , 0.05772064, 0.06699267, 0.02090284,\n",
       "        0.01887001, 0.08000748, 0.13671113, 0.02867457, 0.0921894 ,\n",
       "        0.12744363, 0.09833985, 0.02135718, 0.03185585, 0.02680489,\n",
       "        0.0354897 , 0.00504591, 0.05898279, 0.06210306, 0.05041007,\n",
       "        0.01775045, 0.00828511, 0.01770155, 0.05536328, 0.00571679,\n",
       "        0.03372776, 0.09776044, 0.12589064, 0.00356612, 0.04287361,\n",
       "        0.0111871 , 0.06202906, 0.02165768, 0.03606116, 0.05215359,\n",
       "        0.01324204, 0.00701495, 0.01795354, 0.01543513, 0.01064568,\n",
       "        0.00519806, 0.00729645, 0.02472076, 0.01439835, 0.00691167,\n",
       "        0.00792833, 0.01764827, 0.0090293 , 0.00635046, 0.00579811,\n",
       "        0.02396459, 0.05437101, 0.00699843, 0.02240034, 0.01688407,\n",
       "        0.03963744, 0.01230994, 0.01532654, 0.0541121 , 0.00974564,\n",
       "        0.00488326, 0.00589367, 0.03655033, 0.0821162 , 0.02119494,\n",
       "        0.02544226, 0.03680916, 0.03447304, 0.01510462, 0.03401085,\n",
       "        0.02016347, 0.04756472]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_leaf_nodes': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    32, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    32, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    32, 32],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 2, 2, 2, 6, 6, 6, 6, 20, 20, 20, 20, 2, 2, 2, 2, 6,\n",
       "                    6, 6, 6, 20, 20, 20, 20, 2, 2, 2, 2, 6, 6, 6, 6, 20,\n",
       "                    20, 20, 20, 2, 2, 2, 2, 6, 6, 6, 6, 20, 20, 20, 20, 2,\n",
       "                    2, 2, 2, 6, 6, 6, 6, 20, 20, 20, 20, 2, 2, 2, 2, 6, 6,\n",
       "                    6, 6, 20, 20, 20, 20, 2, 2, 2, 2, 6, 6, 6, 6, 20, 20,\n",
       "                    20, 20, 2, 2, 2, 2, 6, 6, 6, 6, 20, 20, 20, 20, 2, 2,\n",
       "                    2, 2, 6, 6, 6, 6, 20, 20, 20, 20, 2, 2, 2, 2, 6, 6, 6,\n",
       "                    6, 20, 20, 20, 20, 2, 2, 2, 2, 6, 6, 6, 6, 20, 20, 20,\n",
       "                    20, 2, 2, 2, 2, 6, 6, 6, 6, 20, 20, 20, 20, 2, 2, 2, 2,\n",
       "                    6, 6, 6, 6, 20, 20, 20, 20, 2, 2, 2, 2, 6, 6, 6, 6, 20,\n",
       "                    20, 20, 20, 2, 2, 2, 2, 6, 6, 6, 6, 20, 20, 20, 20, 2,\n",
       "                    2, 2, 2, 6, 6, 6, 6, 20, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 200, 300, 400, 100, 200, 300, 400, 100, 200, 300,\n",
       "                    400, 100, 200, 300, 400, 100, 200, 300, 400, 100, 200,\n",
       "                    300, 400, 100, 200, 300, 400, 100, 200, 300, 400, 100,\n",
       "                    200, 300, 400, 100, 200, 300, 400, 100, 200, 300, 400,\n",
       "                    100, 200, 300, 400, 100, 200, 300, 400, 100, 200, 300,\n",
       "                    400, 100, 200, 300, 400, 100, 200, 300, 400, 100, 200,\n",
       "                    300, 400, 100, 200, 300, 400, 100, 200, 300, 400, 100,\n",
       "                    200, 300, 400, 100, 200, 300, 400, 100, 200, 300, 400,\n",
       "                    100, 200, 300, 400, 100, 200, 300, 400, 100, 200, 300,\n",
       "                    400, 100, 200, 300, 400, 100, 200, 300, 400, 100, 200,\n",
       "                    300, 400, 100, 200, 300, 400, 100, 200, 300, 400, 100,\n",
       "                    200, 300, 400, 100, 200, 300, 400, 100, 200, 300, 400,\n",
       "                    100, 200, 300, 400, 100, 200, 300, 400, 100, 200, 300,\n",
       "                    400, 100, 200, 300, 400, 100, 200, 300, 400, 100, 200,\n",
       "                    300, 400, 100, 200, 300, 400, 100, 200, 300, 400, 100,\n",
       "                    200, 300, 400, 100, 200, 300, 400, 100, 200, 300, 400,\n",
       "                    100, 200, 300, 400, 100, 200, 300, 400, 100, 200, 300,\n",
       "                    400, 100, 200, 300, 400],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_random_state': masked_array(data=[17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_verbose': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 16,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 100,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 300,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'log2',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_samples_leaf': 32,\n",
       "   'min_samples_split': 20,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 17,\n",
       "   'verbose': 2}],\n",
       " 'split0_test_score': array([0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.9122807 , 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.85964912,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.85964912, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.85964912, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.87719298, 0.87719298, 0.85964912, 0.85964912,\n",
       "        0.87719298, 0.87719298, 0.85964912, 0.85964912, 0.87719298,\n",
       "        0.87719298, 0.85964912, 0.85964912, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.9122807 ,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.85964912, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.85964912, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.85964912, 0.89473684, 0.89473684, 0.89473684, 0.87719298,\n",
       "        0.87719298, 0.85964912, 0.85964912, 0.87719298, 0.87719298,\n",
       "        0.85964912, 0.85964912, 0.87719298, 0.87719298, 0.85964912,\n",
       "        0.85964912, 0.87719298, 0.87719298, 0.89473684, 0.87719298,\n",
       "        0.9122807 , 0.9122807 , 0.9122807 , 0.9122807 , 0.89473684,\n",
       "        0.87719298, 0.87719298, 0.89473684, 0.9122807 , 0.9122807 ,\n",
       "        0.9122807 , 0.9122807 , 0.9122807 , 0.9122807 , 0.9122807 ,\n",
       "        0.9122807 , 0.87719298, 0.87719298, 0.87719298, 0.89473684,\n",
       "        0.85964912, 0.87719298, 0.87719298, 0.87719298, 0.85964912,\n",
       "        0.87719298, 0.87719298, 0.87719298, 0.85964912, 0.87719298,\n",
       "        0.87719298, 0.87719298, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.87719298,\n",
       "        0.87719298, 0.89473684, 0.87719298, 0.9122807 , 0.9122807 ,\n",
       "        0.9122807 , 0.9122807 , 0.89473684, 0.87719298, 0.87719298,\n",
       "        0.89473684, 0.9122807 , 0.9122807 , 0.9122807 , 0.9122807 ,\n",
       "        0.9122807 , 0.9122807 , 0.9122807 , 0.9122807 , 0.87719298,\n",
       "        0.87719298, 0.87719298, 0.89473684, 0.85964912, 0.87719298,\n",
       "        0.87719298, 0.87719298, 0.85964912, 0.87719298, 0.87719298,\n",
       "        0.87719298, 0.85964912, 0.87719298, 0.87719298, 0.87719298,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912]),\n",
       " 'split1_test_score': array([0.85964912, 0.80701754, 0.80701754, 0.8245614 , 0.85964912,\n",
       "        0.8245614 , 0.8245614 , 0.84210526, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.84210526, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.84210526, 0.84210526, 0.84210526, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.8245614 , 0.8245614 , 0.8245614 , 0.84210526,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.84210526, 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.84210526, 0.85964912, 0.80701754,\n",
       "        0.80701754, 0.8245614 , 0.85964912, 0.8245614 , 0.8245614 ,\n",
       "        0.84210526, 0.85964912, 0.85964912, 0.85964912, 0.84210526,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.84210526,\n",
       "        0.84210526, 0.84210526, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.84210526, 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.84210526, 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.84210526, 0.84210526, 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.87719298, 0.84210526, 0.8245614 , 0.84210526, 0.84210526,\n",
       "        0.84210526, 0.84210526, 0.84210526, 0.85964912, 0.87719298,\n",
       "        0.89473684, 0.87719298, 0.85964912, 0.87719298, 0.89473684,\n",
       "        0.87719298, 0.85964912, 0.84210526, 0.84210526, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.78947368, 0.8245614 , 0.80701754,\n",
       "        0.8245614 , 0.78947368, 0.8245614 , 0.80701754, 0.8245614 ,\n",
       "        0.78947368, 0.8245614 , 0.80701754, 0.8245614 , 0.84210526,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.87719298, 0.84210526,\n",
       "        0.8245614 , 0.84210526, 0.84210526, 0.84210526, 0.84210526,\n",
       "        0.84210526, 0.85964912, 0.87719298, 0.89473684, 0.87719298,\n",
       "        0.85964912, 0.87719298, 0.89473684, 0.87719298, 0.85964912,\n",
       "        0.84210526, 0.84210526, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.78947368, 0.8245614 , 0.80701754, 0.8245614 , 0.78947368,\n",
       "        0.8245614 , 0.80701754, 0.8245614 , 0.78947368, 0.8245614 ,\n",
       "        0.80701754, 0.8245614 ]),\n",
       " 'split2_test_score': array([0.75438596, 0.73684211, 0.73684211, 0.73684211, 0.84210526,\n",
       "        0.8245614 , 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.84210526, 0.80701754, 0.8245614 ,\n",
       "        0.8245614 , 0.84210526, 0.80701754, 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.84210526, 0.84210526, 0.8245614 , 0.8245614 ,\n",
       "        0.84210526, 0.84210526, 0.8245614 , 0.8245614 , 0.84210526,\n",
       "        0.84210526, 0.78947368, 0.80701754, 0.84210526, 0.8245614 ,\n",
       "        0.78947368, 0.80701754, 0.84210526, 0.8245614 , 0.78947368,\n",
       "        0.80701754, 0.84210526, 0.8245614 , 0.75438596, 0.73684211,\n",
       "        0.73684211, 0.73684211, 0.84210526, 0.8245614 , 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.84210526, 0.80701754, 0.8245614 , 0.8245614 , 0.84210526,\n",
       "        0.80701754, 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.84210526,\n",
       "        0.84210526, 0.8245614 , 0.8245614 , 0.84210526, 0.84210526,\n",
       "        0.8245614 , 0.8245614 , 0.84210526, 0.84210526, 0.78947368,\n",
       "        0.80701754, 0.84210526, 0.8245614 , 0.78947368, 0.80701754,\n",
       "        0.84210526, 0.8245614 , 0.78947368, 0.80701754, 0.84210526,\n",
       "        0.8245614 , 0.71929825, 0.75438596, 0.73684211, 0.73684211,\n",
       "        0.8245614 , 0.8245614 , 0.80701754, 0.80701754, 0.8245614 ,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.84210526, 0.84210526, 0.8245614 ,\n",
       "        0.8245614 , 0.84210526, 0.84210526, 0.8245614 , 0.8245614 ,\n",
       "        0.84210526, 0.84210526, 0.78947368, 0.8245614 , 0.84210526,\n",
       "        0.8245614 , 0.78947368, 0.8245614 , 0.84210526, 0.8245614 ,\n",
       "        0.78947368, 0.8245614 , 0.84210526, 0.8245614 , 0.71929825,\n",
       "        0.75438596, 0.73684211, 0.73684211, 0.8245614 , 0.8245614 ,\n",
       "        0.80701754, 0.80701754, 0.8245614 , 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.84210526, 0.84210526, 0.8245614 , 0.8245614 , 0.84210526,\n",
       "        0.84210526, 0.8245614 , 0.8245614 , 0.84210526, 0.84210526,\n",
       "        0.78947368, 0.8245614 , 0.84210526, 0.8245614 , 0.78947368,\n",
       "        0.8245614 , 0.84210526, 0.8245614 , 0.78947368, 0.8245614 ,\n",
       "        0.84210526, 0.8245614 ]),\n",
       " 'split3_test_score': array([0.8245614 , 0.8245614 , 0.80701754, 0.8245614 , 0.8245614 ,\n",
       "        0.84210526, 0.84210526, 0.84210526, 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.85964912, 0.80701754, 0.8245614 , 0.8245614 , 0.78947368,\n",
       "        0.78947368, 0.80701754, 0.75438596, 0.78947368, 0.78947368,\n",
       "        0.80701754, 0.75438596, 0.78947368, 0.78947368, 0.80701754,\n",
       "        0.75438596, 0.75438596, 0.75438596, 0.73684211, 0.73684211,\n",
       "        0.75438596, 0.75438596, 0.73684211, 0.73684211, 0.75438596,\n",
       "        0.75438596, 0.73684211, 0.73684211, 0.8245614 , 0.8245614 ,\n",
       "        0.80701754, 0.8245614 , 0.8245614 , 0.84210526, 0.84210526,\n",
       "        0.84210526, 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.85964912, 0.80701754,\n",
       "        0.8245614 , 0.8245614 , 0.78947368, 0.78947368, 0.80701754,\n",
       "        0.75438596, 0.78947368, 0.78947368, 0.80701754, 0.75438596,\n",
       "        0.78947368, 0.78947368, 0.80701754, 0.75438596, 0.75438596,\n",
       "        0.75438596, 0.73684211, 0.73684211, 0.75438596, 0.75438596,\n",
       "        0.73684211, 0.73684211, 0.75438596, 0.75438596, 0.73684211,\n",
       "        0.73684211, 0.8245614 , 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.8245614 , 0.85964912, 0.85964912, 0.8245614 ,\n",
       "        0.8245614 , 0.80701754, 0.8245614 , 0.84210526, 0.84210526,\n",
       "        0.8245614 , 0.8245614 , 0.84210526, 0.84210526, 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.77192982, 0.77192982, 0.75438596, 0.75438596, 0.77192982,\n",
       "        0.77192982, 0.75438596, 0.75438596, 0.77192982, 0.77192982,\n",
       "        0.75438596, 0.75438596, 0.77192982, 0.75438596, 0.73684211,\n",
       "        0.73684211, 0.77192982, 0.75438596, 0.73684211, 0.73684211,\n",
       "        0.77192982, 0.75438596, 0.73684211, 0.73684211, 0.8245614 ,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.8245614 ,\n",
       "        0.85964912, 0.85964912, 0.8245614 , 0.8245614 , 0.80701754,\n",
       "        0.8245614 , 0.84210526, 0.84210526, 0.8245614 , 0.8245614 ,\n",
       "        0.84210526, 0.84210526, 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.77192982, 0.77192982,\n",
       "        0.75438596, 0.75438596, 0.77192982, 0.77192982, 0.75438596,\n",
       "        0.75438596, 0.77192982, 0.77192982, 0.75438596, 0.75438596,\n",
       "        0.77192982, 0.75438596, 0.73684211, 0.73684211, 0.77192982,\n",
       "        0.75438596, 0.73684211, 0.73684211, 0.77192982, 0.75438596,\n",
       "        0.73684211, 0.73684211]),\n",
       " 'split4_test_score': array([0.8245614 , 0.84210526, 0.8245614 , 0.8245614 , 0.84210526,\n",
       "        0.84210526, 0.85964912, 0.85964912, 0.84210526, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.87719298, 0.87719298, 0.85964912,\n",
       "        0.85964912, 0.87719298, 0.87719298, 0.85964912, 0.85964912,\n",
       "        0.84210526, 0.84210526, 0.85964912, 0.85964912, 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.78947368, 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.78947368, 0.8245614 , 0.8245614 , 0.8245614 , 0.78947368,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.84210526,\n",
       "        0.8245614 , 0.8245614 , 0.84210526, 0.84210526, 0.85964912,\n",
       "        0.85964912, 0.84210526, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.87719298, 0.87719298, 0.85964912, 0.85964912, 0.87719298,\n",
       "        0.87719298, 0.85964912, 0.85964912, 0.84210526, 0.84210526,\n",
       "        0.85964912, 0.85964912, 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.78947368,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.78947368, 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.78947368, 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.85964912, 0.84210526, 0.85964912, 0.84210526,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.84210526,\n",
       "        0.84210526, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.87719298, 0.87719298, 0.85964912, 0.85964912, 0.87719298,\n",
       "        0.87719298, 0.85964912, 0.84210526, 0.84210526, 0.85964912,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.78947368, 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.78947368, 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.78947368, 0.8245614 , 0.8245614 , 0.8245614 , 0.85964912,\n",
       "        0.84210526, 0.85964912, 0.84210526, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.84210526, 0.84210526, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.87719298, 0.87719298,\n",
       "        0.85964912, 0.85964912, 0.87719298, 0.87719298, 0.85964912,\n",
       "        0.84210526, 0.84210526, 0.85964912, 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.78947368, 0.8245614 , 0.8245614 , 0.8245614 , 0.78947368,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.78947368, 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 ]),\n",
       " 'split5_test_score': array([0.78947368, 0.78947368, 0.78947368, 0.77192982, 0.77192982,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.77192982, 0.78947368,\n",
       "        0.77192982, 0.77192982, 0.77192982, 0.80701754, 0.78947368,\n",
       "        0.78947368, 0.77192982, 0.80701754, 0.78947368, 0.78947368,\n",
       "        0.77192982, 0.78947368, 0.77192982, 0.77192982, 0.77192982,\n",
       "        0.73684211, 0.75438596, 0.73684211, 0.77192982, 0.73684211,\n",
       "        0.75438596, 0.73684211, 0.77192982, 0.73684211, 0.75438596,\n",
       "        0.73684211, 0.77192982, 0.77192982, 0.77192982, 0.77192982,\n",
       "        0.77192982, 0.77192982, 0.77192982, 0.77192982, 0.77192982,\n",
       "        0.77192982, 0.77192982, 0.77192982, 0.78947368, 0.78947368,\n",
       "        0.78947368, 0.77192982, 0.77192982, 0.78947368, 0.78947368,\n",
       "        0.78947368, 0.77192982, 0.78947368, 0.77192982, 0.77192982,\n",
       "        0.77192982, 0.80701754, 0.78947368, 0.78947368, 0.77192982,\n",
       "        0.80701754, 0.78947368, 0.78947368, 0.77192982, 0.78947368,\n",
       "        0.77192982, 0.77192982, 0.77192982, 0.73684211, 0.75438596,\n",
       "        0.73684211, 0.77192982, 0.73684211, 0.75438596, 0.73684211,\n",
       "        0.77192982, 0.73684211, 0.75438596, 0.73684211, 0.77192982,\n",
       "        0.77192982, 0.77192982, 0.77192982, 0.77192982, 0.77192982,\n",
       "        0.77192982, 0.77192982, 0.77192982, 0.77192982, 0.77192982,\n",
       "        0.77192982, 0.75438596, 0.77192982, 0.78947368, 0.77192982,\n",
       "        0.77192982, 0.77192982, 0.75438596, 0.77192982, 0.77192982,\n",
       "        0.73684211, 0.75438596, 0.75438596, 0.77192982, 0.77192982,\n",
       "        0.75438596, 0.78947368, 0.77192982, 0.77192982, 0.75438596,\n",
       "        0.78947368, 0.75438596, 0.78947368, 0.77192982, 0.75438596,\n",
       "        0.75438596, 0.73684211, 0.75438596, 0.73684211, 0.75438596,\n",
       "        0.73684211, 0.75438596, 0.73684211, 0.75438596, 0.73684211,\n",
       "        0.75438596, 0.73684211, 0.77192982, 0.77192982, 0.77192982,\n",
       "        0.77192982, 0.77192982, 0.77192982, 0.77192982, 0.77192982,\n",
       "        0.77192982, 0.77192982, 0.77192982, 0.77192982, 0.75438596,\n",
       "        0.77192982, 0.78947368, 0.77192982, 0.77192982, 0.77192982,\n",
       "        0.75438596, 0.77192982, 0.77192982, 0.73684211, 0.75438596,\n",
       "        0.75438596, 0.77192982, 0.77192982, 0.75438596, 0.78947368,\n",
       "        0.77192982, 0.77192982, 0.75438596, 0.78947368, 0.75438596,\n",
       "        0.78947368, 0.77192982, 0.75438596, 0.75438596, 0.73684211,\n",
       "        0.75438596, 0.73684211, 0.75438596, 0.73684211, 0.75438596,\n",
       "        0.73684211, 0.75438596, 0.73684211, 0.75438596, 0.73684211,\n",
       "        0.77192982, 0.77192982, 0.77192982, 0.77192982, 0.77192982,\n",
       "        0.77192982, 0.77192982, 0.77192982, 0.77192982, 0.77192982,\n",
       "        0.77192982, 0.77192982]),\n",
       " 'split6_test_score': array([0.77192982, 0.77192982, 0.77192982, 0.77192982, 0.8245614 ,\n",
       "        0.80701754, 0.80701754, 0.78947368, 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.80701754, 0.80701754, 0.80701754, 0.8245614 ,\n",
       "        0.8245614 , 0.80701754, 0.80701754, 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.71929825, 0.73684211, 0.73684211, 0.73684211,\n",
       "        0.71929825, 0.73684211, 0.73684211, 0.73684211, 0.71929825,\n",
       "        0.73684211, 0.73684211, 0.73684211, 0.77192982, 0.77192982,\n",
       "        0.77192982, 0.77192982, 0.8245614 , 0.80701754, 0.80701754,\n",
       "        0.78947368, 0.8245614 , 0.8245614 , 0.8245614 , 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.8245614 , 0.8245614 , 0.80701754,\n",
       "        0.80701754, 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.71929825,\n",
       "        0.73684211, 0.73684211, 0.73684211, 0.71929825, 0.73684211,\n",
       "        0.73684211, 0.73684211, 0.71929825, 0.73684211, 0.73684211,\n",
       "        0.73684211, 0.78947368, 0.77192982, 0.77192982, 0.77192982,\n",
       "        0.80701754, 0.80701754, 0.8245614 , 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.75438596, 0.71929825, 0.73684211,\n",
       "        0.71929825, 0.75438596, 0.71929825, 0.73684211, 0.71929825,\n",
       "        0.75438596, 0.71929825, 0.73684211, 0.71929825, 0.78947368,\n",
       "        0.77192982, 0.77192982, 0.77192982, 0.80701754, 0.80701754,\n",
       "        0.8245614 , 0.80701754, 0.80701754, 0.80701754, 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.75438596, 0.71929825, 0.73684211, 0.71929825, 0.75438596,\n",
       "        0.71929825, 0.73684211, 0.71929825, 0.75438596, 0.71929825,\n",
       "        0.73684211, 0.71929825]),\n",
       " 'split7_test_score': array([0.84210526, 0.84210526, 0.84210526, 0.84210526, 0.87719298,\n",
       "        0.85964912, 0.87719298, 0.87719298, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.87719298, 0.87719298, 0.89473684, 0.87719298,\n",
       "        0.85964912, 0.87719298, 0.89473684, 0.87719298, 0.85964912,\n",
       "        0.87719298, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.84210526, 0.8245614 , 0.8245614 , 0.85964912, 0.84210526,\n",
       "        0.8245614 , 0.8245614 , 0.85964912, 0.84210526, 0.8245614 ,\n",
       "        0.8245614 , 0.80701754, 0.78947368, 0.8245614 , 0.80701754,\n",
       "        0.80701754, 0.78947368, 0.8245614 , 0.80701754, 0.80701754,\n",
       "        0.78947368, 0.8245614 , 0.80701754, 0.84210526, 0.84210526,\n",
       "        0.84210526, 0.84210526, 0.87719298, 0.85964912, 0.87719298,\n",
       "        0.87719298, 0.89473684, 0.89473684, 0.89473684, 0.87719298,\n",
       "        0.87719298, 0.89473684, 0.87719298, 0.85964912, 0.87719298,\n",
       "        0.89473684, 0.87719298, 0.85964912, 0.87719298, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.84210526, 0.8245614 ,\n",
       "        0.8245614 , 0.85964912, 0.84210526, 0.8245614 , 0.8245614 ,\n",
       "        0.85964912, 0.84210526, 0.8245614 , 0.8245614 , 0.80701754,\n",
       "        0.78947368, 0.8245614 , 0.80701754, 0.80701754, 0.78947368,\n",
       "        0.8245614 , 0.80701754, 0.80701754, 0.78947368, 0.8245614 ,\n",
       "        0.80701754, 0.84210526, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.87719298, 0.87719298,\n",
       "        0.85964912, 0.85964912, 0.87719298, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.84210526, 0.84210526, 0.85964912,\n",
       "        0.85964912, 0.84210526, 0.84210526, 0.8245614 , 0.85964912,\n",
       "        0.84210526, 0.84210526, 0.8245614 , 0.85964912, 0.84210526,\n",
       "        0.84210526, 0.8245614 , 0.78947368, 0.78947368, 0.80701754,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.80701754, 0.78947368,\n",
       "        0.78947368, 0.78947368, 0.80701754, 0.78947368, 0.84210526,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.87719298, 0.87719298, 0.85964912, 0.85964912,\n",
       "        0.87719298, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.85964912, 0.85964912, 0.85964912, 0.85964912, 0.85964912,\n",
       "        0.84210526, 0.84210526, 0.85964912, 0.85964912, 0.84210526,\n",
       "        0.84210526, 0.8245614 , 0.85964912, 0.84210526, 0.84210526,\n",
       "        0.8245614 , 0.85964912, 0.84210526, 0.84210526, 0.8245614 ,\n",
       "        0.78947368, 0.78947368, 0.80701754, 0.78947368, 0.78947368,\n",
       "        0.78947368, 0.80701754, 0.78947368, 0.78947368, 0.78947368,\n",
       "        0.80701754, 0.78947368]),\n",
       " 'split8_test_score': array([0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.80701754, 0.8245614 , 0.78947368, 0.80701754,\n",
       "        0.77192982, 0.77192982, 0.8245614 , 0.80701754, 0.78947368,\n",
       "        0.78947368, 0.8245614 , 0.80701754, 0.78947368, 0.78947368,\n",
       "        0.80701754, 0.80701754, 0.77192982, 0.78947368, 0.78947368,\n",
       "        0.80701754, 0.80701754, 0.80701754, 0.78947368, 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.78947368, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.78947368, 0.78947368, 0.80701754,\n",
       "        0.80701754, 0.78947368, 0.78947368, 0.80701754, 0.80701754,\n",
       "        0.78947368, 0.78947368, 0.80701754, 0.8245614 , 0.8245614 ,\n",
       "        0.8245614 , 0.8245614 , 0.8245614 , 0.8245614 , 0.80701754,\n",
       "        0.8245614 , 0.78947368, 0.80701754, 0.77192982, 0.77192982,\n",
       "        0.8245614 , 0.80701754, 0.78947368, 0.78947368, 0.8245614 ,\n",
       "        0.80701754, 0.78947368, 0.78947368, 0.80701754, 0.80701754,\n",
       "        0.77192982, 0.78947368, 0.78947368, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.78947368, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.78947368, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.78947368, 0.78947368, 0.80701754, 0.80701754, 0.78947368,\n",
       "        0.78947368, 0.80701754, 0.80701754, 0.78947368, 0.78947368,\n",
       "        0.80701754, 0.80701754, 0.84210526, 0.84210526, 0.8245614 ,\n",
       "        0.80701754, 0.8245614 , 0.8245614 , 0.80701754, 0.8245614 ,\n",
       "        0.77192982, 0.75438596, 0.78947368, 0.78947368, 0.78947368,\n",
       "        0.78947368, 0.80701754, 0.78947368, 0.78947368, 0.78947368,\n",
       "        0.80701754, 0.78947368, 0.78947368, 0.78947368, 0.80701754,\n",
       "        0.78947368, 0.78947368, 0.80701754, 0.78947368, 0.78947368,\n",
       "        0.78947368, 0.80701754, 0.78947368, 0.78947368, 0.78947368,\n",
       "        0.80701754, 0.78947368, 0.80701754, 0.78947368, 0.80701754,\n",
       "        0.80701754, 0.80701754, 0.78947368, 0.80701754, 0.80701754,\n",
       "        0.80701754, 0.78947368, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.84210526, 0.84210526, 0.8245614 , 0.80701754, 0.8245614 ,\n",
       "        0.8245614 , 0.80701754, 0.8245614 , 0.77192982, 0.75438596,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.80701754,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.80701754, 0.78947368,\n",
       "        0.78947368, 0.78947368, 0.80701754, 0.78947368, 0.78947368,\n",
       "        0.80701754, 0.78947368, 0.78947368, 0.78947368, 0.80701754,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.80701754, 0.78947368,\n",
       "        0.80701754, 0.78947368, 0.80701754, 0.80701754, 0.80701754,\n",
       "        0.78947368, 0.80701754, 0.80701754, 0.80701754, 0.78947368,\n",
       "        0.80701754, 0.80701754]),\n",
       " 'split9_test_score': array([0.80357143, 0.82142857, 0.82142857, 0.80357143, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.83928571, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.875     ,\n",
       "        0.85714286, 0.875     , 0.83928571, 0.875     , 0.85714286,\n",
       "        0.875     , 0.83928571, 0.875     , 0.85714286, 0.875     ,\n",
       "        0.83928571, 0.82142857, 0.82142857, 0.83928571, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.83928571, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.83928571, 0.82142857, 0.80357143, 0.82142857,\n",
       "        0.82142857, 0.80357143, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.83928571, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.875     , 0.85714286, 0.875     ,\n",
       "        0.83928571, 0.875     , 0.85714286, 0.875     , 0.83928571,\n",
       "        0.875     , 0.85714286, 0.875     , 0.83928571, 0.82142857,\n",
       "        0.82142857, 0.83928571, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.83928571, 0.82142857, 0.82142857, 0.82142857, 0.83928571,\n",
       "        0.82142857, 0.80357143, 0.80357143, 0.80357143, 0.80357143,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.85714286, 0.83928571, 0.83928571, 0.85714286, 0.85714286,\n",
       "        0.83928571, 0.83928571, 0.85714286, 0.85714286, 0.83928571,\n",
       "        0.83928571, 0.85714286, 0.82142857, 0.82142857, 0.83928571,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.83928571, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.83928571, 0.82142857, 0.80357143,\n",
       "        0.80357143, 0.80357143, 0.80357143, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.82142857, 0.82142857, 0.85714286, 0.83928571,\n",
       "        0.83928571, 0.85714286, 0.85714286, 0.83928571, 0.83928571,\n",
       "        0.85714286, 0.85714286, 0.83928571, 0.83928571, 0.85714286,\n",
       "        0.82142857, 0.82142857, 0.83928571, 0.82142857, 0.82142857,\n",
       "        0.82142857, 0.83928571, 0.82142857, 0.82142857, 0.82142857,\n",
       "        0.83928571, 0.82142857]),\n",
       " 'mean_test_score': array([0.81895363, 0.81547619, 0.81196742, 0.81193609, 0.83828321,\n",
       "        0.83302005, 0.83302005, 0.83477444, 0.83480576, 0.83828321,\n",
       "        0.83302005, 0.82951128, 0.84003759, 0.84003759, 0.83652882,\n",
       "        0.83477444, 0.84003759, 0.84003759, 0.83652882, 0.83477444,\n",
       "        0.83828321, 0.83126566, 0.82775689, 0.82951128, 0.82609649,\n",
       "        0.82431078, 0.82960526, 0.81901629, 0.82609649, 0.82431078,\n",
       "        0.82960526, 0.81901629, 0.82609649, 0.82431078, 0.82960526,\n",
       "        0.81901629, 0.79617794, 0.79968672, 0.8049812 , 0.80319549,\n",
       "        0.79617794, 0.79968672, 0.8049812 , 0.80319549, 0.79617794,\n",
       "        0.79968672, 0.8049812 , 0.80319549, 0.81895363, 0.81547619,\n",
       "        0.81196742, 0.81193609, 0.83828321, 0.83302005, 0.83302005,\n",
       "        0.83477444, 0.83480576, 0.83828321, 0.83302005, 0.82951128,\n",
       "        0.84003759, 0.84003759, 0.83652882, 0.83477444, 0.84003759,\n",
       "        0.84003759, 0.83652882, 0.83477444, 0.83828321, 0.83126566,\n",
       "        0.82775689, 0.82951128, 0.82609649, 0.82431078, 0.82960526,\n",
       "        0.81901629, 0.82609649, 0.82431078, 0.82960526, 0.81901629,\n",
       "        0.82609649, 0.82431078, 0.82960526, 0.81901629, 0.79617794,\n",
       "        0.79968672, 0.8049812 , 0.80319549, 0.79617794, 0.79968672,\n",
       "        0.8049812 , 0.80319549, 0.79617794, 0.79968672, 0.8049812 ,\n",
       "        0.80319549, 0.81193609, 0.81544486, 0.81895363, 0.81193609,\n",
       "        0.83477444, 0.83477444, 0.83477444, 0.83652882, 0.83302005,\n",
       "        0.81898496, 0.82073935, 0.82951128, 0.83652882, 0.83828321,\n",
       "        0.83828321, 0.84179198, 0.83652882, 0.83828321, 0.83828321,\n",
       "        0.84179198, 0.82951128, 0.82600251, 0.82424812, 0.83126566,\n",
       "        0.82080201, 0.8172619 , 0.82077068, 0.81729323, 0.82080201,\n",
       "        0.8172619 , 0.82077068, 0.81729323, 0.82080201, 0.8172619 ,\n",
       "        0.82077068, 0.81729323, 0.79442356, 0.79793233, 0.80322682,\n",
       "        0.79793233, 0.79442356, 0.79793233, 0.80322682, 0.79793233,\n",
       "        0.79442356, 0.79793233, 0.80322682, 0.79793233, 0.81193609,\n",
       "        0.81544486, 0.81895363, 0.81193609, 0.83477444, 0.83477444,\n",
       "        0.83477444, 0.83652882, 0.83302005, 0.81898496, 0.82073935,\n",
       "        0.82951128, 0.83652882, 0.83828321, 0.83828321, 0.84179198,\n",
       "        0.83652882, 0.83828321, 0.83828321, 0.84179198, 0.82951128,\n",
       "        0.82600251, 0.82424812, 0.83126566, 0.82080201, 0.8172619 ,\n",
       "        0.82077068, 0.81729323, 0.82080201, 0.8172619 , 0.82077068,\n",
       "        0.81729323, 0.82080201, 0.8172619 , 0.82077068, 0.81729323,\n",
       "        0.79442356, 0.79793233, 0.80322682, 0.79793233, 0.79442356,\n",
       "        0.79793233, 0.80322682, 0.79793233, 0.79442356, 0.79793233,\n",
       "        0.80322682, 0.79793233]),\n",
       " 'std_test_score': array([0.03938967, 0.0409002 , 0.03995947, 0.04160987, 0.03230854,\n",
       "        0.0275764 , 0.03268401, 0.03358308, 0.03855447, 0.03505016,\n",
       "        0.0417777 , 0.04233702, 0.0356318 , 0.0356318 , 0.03346176,\n",
       "        0.03169714, 0.0356318 , 0.0356318 , 0.03346176, 0.03169714,\n",
       "        0.03416074, 0.02859787, 0.03667469, 0.03430524, 0.03428425,\n",
       "        0.04131083, 0.03821142, 0.04428057, 0.03428425, 0.04131083,\n",
       "        0.03821142, 0.04428057, 0.03428425, 0.04131083, 0.03821142,\n",
       "        0.04428057, 0.04071433, 0.03840811, 0.04160827, 0.03969727,\n",
       "        0.04071433, 0.03840811, 0.04160827, 0.03969727, 0.04071433,\n",
       "        0.03840811, 0.04160827, 0.03969727, 0.03938967, 0.0409002 ,\n",
       "        0.03995947, 0.04160987, 0.03230854, 0.0275764 , 0.03268401,\n",
       "        0.03358308, 0.03855447, 0.03505016, 0.0417777 , 0.04233702,\n",
       "        0.0356318 , 0.0356318 , 0.03346176, 0.03169714, 0.0356318 ,\n",
       "        0.0356318 , 0.03346176, 0.03169714, 0.03416074, 0.02859787,\n",
       "        0.03667469, 0.03430524, 0.03428425, 0.04131083, 0.03821142,\n",
       "        0.04428057, 0.03428425, 0.04131083, 0.03821142, 0.04428057,\n",
       "        0.03428425, 0.04131083, 0.03821142, 0.04428057, 0.04071433,\n",
       "        0.03840811, 0.04160827, 0.03969727, 0.04071433, 0.03840811,\n",
       "        0.04160827, 0.03969727, 0.04071433, 0.03840811, 0.04160827,\n",
       "        0.03969727, 0.04583368, 0.03872831, 0.04452469, 0.04086348,\n",
       "        0.0394807 , 0.03536861, 0.0394807 , 0.03937754, 0.03268401,\n",
       "        0.03923772, 0.03983548, 0.03932167, 0.03778195, 0.03919567,\n",
       "        0.04571999, 0.03611899, 0.03778195, 0.03919567, 0.04571999,\n",
       "        0.03611899, 0.03519101, 0.02540192, 0.02830423, 0.03703856,\n",
       "        0.03721193, 0.03999586, 0.038929  , 0.04358957, 0.03721193,\n",
       "        0.03999586, 0.038929  , 0.04358957, 0.03721193, 0.03999586,\n",
       "        0.038929  , 0.04358957, 0.02802714, 0.03922651, 0.04035702,\n",
       "        0.04151375, 0.02802714, 0.03922651, 0.04035702, 0.04151375,\n",
       "        0.02802714, 0.03922651, 0.04035702, 0.04151375, 0.04583368,\n",
       "        0.03872831, 0.04452469, 0.04086348, 0.0394807 , 0.03536861,\n",
       "        0.0394807 , 0.03937754, 0.03268401, 0.03923772, 0.03983548,\n",
       "        0.03932167, 0.03778195, 0.03919567, 0.04571999, 0.03611899,\n",
       "        0.03778195, 0.03919567, 0.04571999, 0.03611899, 0.03519101,\n",
       "        0.02540192, 0.02830423, 0.03703856, 0.03721193, 0.03999586,\n",
       "        0.038929  , 0.04358957, 0.03721193, 0.03999586, 0.038929  ,\n",
       "        0.04358957, 0.03721193, 0.03999586, 0.038929  , 0.04358957,\n",
       "        0.02802714, 0.03922651, 0.04035702, 0.04151375, 0.02802714,\n",
       "        0.03922651, 0.04035702, 0.04151375, 0.02802714, 0.03922651,\n",
       "        0.04035702, 0.04151375]),\n",
       " 'rank_test_score': array([117, 133, 137, 139,  13,  51,  51,  39,  37,  13,  51,  69,   5,\n",
       "          5,  27,  39,   5,   5,  27,  39,  13,  59,  77,  69,  79,  87,\n",
       "         63, 109,  79,  87,  63, 109,  79,  87,  63, 109, 181, 163, 145,\n",
       "        157, 181, 163, 145, 157, 181, 163, 145, 157, 117, 133, 137, 139,\n",
       "         13,  51,  51,  39,  37,  13,  51,  69,   5,   5,  27,  39,   5,\n",
       "          5,  27,  39,  13,  59,  77,  69,  79,  87,  63, 109,  79,  87,\n",
       "         63, 109,  79,  87,  63, 109, 181, 163, 145, 157, 181, 163, 145,\n",
       "        157, 181, 163, 145, 157, 139, 135, 119, 139,  49,  39,  39,  35,\n",
       "         51, 115, 107,  69,  27,  13,  13,   1,  27,  13,  13,   1,  69,\n",
       "         85,  93,  59,  95, 127, 101, 121,  95, 127, 101, 121,  95, 127,\n",
       "        101, 121, 187, 169, 151, 169, 187, 169, 151, 169, 187, 169, 151,\n",
       "        169, 139, 135, 119, 139,  49,  39,  39,  35,  51, 115, 107,  69,\n",
       "         27,  13,  13,   1,  27,  13,  13,   1,  69,  85,  93,  59,  95,\n",
       "        127, 101, 121,  95, 127, 101, 121,  95, 127, 101, 121, 187, 169,\n",
       "        151, 169, 187, 169, 151, 169, 187, 169, 151, 169], dtype=int32)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsRF.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicamos el resultado final del modelo obtenido y lo aplicamos primero al Validation y luego al Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos el modelo al validación\n",
    "data_val = gsLDA.predict(<dataset de validación>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 35)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape # 143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape #418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Sucesivamente hay que aplicarlo al testing dataset\n",
    "prediction = gsRF.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los resultados de nuestro modelo aplicado al dataset de test \n",
    "submission = pd.DataFrame({\n",
    "  'PassengerId' : ids,\n",
    "    'Survived' : prediction\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('titanic_model.gsRF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived\n",
       "0           892         0\n",
       "1           893         0\n",
       "2           894         0\n",
       "3           895         0\n",
       "4           896         1\n",
       "5           897         0\n",
       "6           898         1\n",
       "7           899         0\n",
       "8           900         1\n",
       "9           901         0\n",
       "10          902         0\n",
       "11          903         0\n",
       "12          904         1\n",
       "13          905         0\n",
       "14          906         1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jovyan/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 2.77k/2.77k [00:02<00:00, 1.41kB/s]\n",
      "Successfully submitted to Titanic - Machine Learning from Disaster"
     ]
    }
   ],
   "source": [
    "# Submission to Kaggle\n",
    "!kaggle competitions submit titanic -f 'titanic_model.gsRF.csv' -m \"Modelo ML utilizado tuning RF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jovyan/.kaggle/kaggle.json'\n",
      "fileName                         date                 description                                                                                                                 status    publicScore  privateScore  \n",
      "-------------------------------  -------------------  --------------------------------------------------------------------------------------------------------------------------  --------  -----------  ------------  \n",
      "titanic_model.gsRF.csv           2021-03-13 12:44:42  Modelo ML utilizado tuning LR                                                                                               complete  0.74880      None          \n",
      "titanic_model.gsLR.csv           2021-03-13 11:30:48  Modelo ML utilizado tuning LR                                                                                               complete  0.77272      None          \n",
      "titanic_model.gsLDA.csv          2021-03-13 09:36:24  Modelo ML utilizado tuning LDA                                                                                              complete  0.77272      None          \n",
      "submission_SVC2.csv              2021-03-12 19:55:54  SVC 2                                                                                                                       complete  0.78468      None          \n",
      "titanic_model.gsGBC2.csv         2021-03-12 19:31:42  Modelo ML utilizado XYZ                                                                                                     complete  0.74641      None          \n",
      "submission_VP1.csv               2020-05-05 13:59:49  VP1 cols15                                                                                                                  complete  0.78229      None          \n",
      "submission-simple-cleansing.csv  2020-05-05 09:27:50  keras example                                                                                                               complete  0.75358      None          \n",
      "evaluation_submission_nn.csv     2020-05-04 19:04:51  submit NN results                                                                                                           complete  0.25598      None          \n",
      "gender_submission.csv            2020-05-04 17:55:11  test gender submission                                                                                                      complete  0.76555      None          \n",
      "submission_DT.csv                2020-04-16 11:05:18  DecisionTree colsRNK10                                                                                                      complete  0.76555      None          \n",
      "submission_VP1.csv               2020-04-12 18:35:01  VP1 colsRNK5                                                                                                                complete  0.78947      None          \n",
      "submission_SVC2.csv              2020-04-12 17:35:51  SVC colsSPT                                                                                                                 complete  0.80861      None          \n",
      "submission_SVC.csv               2020-04-12 17:33:27  SVC colsRNK15                                                                                                               complete  0.80861      None          \n",
      "submission_KNN2.csv              2020-04-12 17:16:23  KNN colsRNK15                                                                                                               complete  0.77511      None          \n",
      "submission_KNN.csv               2020-04-12 17:08:31  KNN colsSPT                                                                                                                 complete  0.74162      None          \n",
      "submission_RF2.csv               2020-04-12 16:39:18  Random Forest colsRNK10                                                                                                     complete  0.79425      None          \n",
      "submission_RF.csv                2020-04-12 16:34:01  Random Forest colsRNK5                                                                                                      complete  0.76076      None          \n",
      "submission_DT.csv                2020-04-12 15:10:07  DecisionTree colsRNK5                                                                                                       complete  0.75119      None          \n",
      "submission_LR.csv                2020-04-12 13:37:57  LogisticRegression colsSPT                                                                                                  complete  0.78468      None          \n",
      "evaluation_submission_nn.csv     2020-03-31 17:32:19  submit NN results                                                                                                           complete  0.22966      None          \n",
      "k_neighbours.csv                 2020-03-07 16:54:01  test                                                                                                                        complete  0.77511      None          \n",
      "titanic_model_15.csv             2020-02-17 20:35:24  first 1.5a                                                                                                                  complete  0.77511      None          \n",
      "titanic_model_15.csv             2020-02-17 19:40:57  version 1.5                                                                                                                 complete  0.00000      None          \n",
      "titanic_model.csv                2020-02-03 20:35:09  Voting Predictor with 18 features                                                                                           complete  0.77990      None          \n",
      "titanic_model.csv                2020-02-02 18:11:45  Version VotingPredictor 84%                                                                                                 complete  0.78468      None          \n",
      "submission_sv_3.csv              2020-01-27 22:21:52  SVM w/o age                                                                                                                 complete  0.76555      None          \n",
      "submission_rf_3.csv              2020-01-27 22:21:14  random forest w/o age                                                                                                       complete  0.75119      None          \n",
      "submission_lr_3.csv              2020-01-27 22:20:27  log reg without age                                                                                                         complete  0.76555      None          \n",
      "submission_knn_3.csv             2020-01-27 22:20:03  knn without age                                                                                                             complete  0.72248      None          \n",
      "submission_dt_3.csv              2020-01-27 22:17:26  drop others features - Age                                                                                                  complete  0.78468      None          \n",
      "submission_dt_3.csv              2020-01-19 18:58:32  decision tree v3                                                                                                            complete  0.69856      None          \n",
      "submission_sv_3.csv              2020-01-19 18:58:13  SVM v3                                                                                                                      complete  0.75119      None          \n",
      "submission_rf_3.csv              2020-01-19 18:57:55  random forest v3                                                                                                            complete  0.76555      None          \n",
      "submission_lr_3.csv              2020-01-19 18:57:39  logistc regression v3                                                                                                       complete  0.76076      None          \n",
      "submission_rf_2.csv              2020-01-19 18:36:01  random forest v2 and 32 features                                                                                            complete  0.75119      None          \n",
      "submission_sv_2.csv              2020-01-19 18:34:16  \n",
      "SVM v2 and only 32 features                                                                                                complete  0.78468      None          \n",
      "submission_rf_2.csv              2020-01-19 18:33:45  random forest v2 and only 32 features                                                                                       error     None         None          \n",
      "submission_lr_2.csv              2020-01-19 18:33:22  logistic regression v2 and only 32 features                                                                                 complete  0.78947      None          \n",
      "submission_dt_2.csv              2020-01-19 18:32:54  decision tree v2 and only 32 features                                                                                       complete  0.68899      None          \n",
      "submission_rf_2.csv              2020-01-18 23:05:27  randomForest v2                                                                                                             complete  0.77033      None          \n",
      "submission_dt_2.csv              2020-01-18 23:03:56  dt v2                                                                                                                       complete  0.75598      None          \n",
      "submission_sv_2.csv              2020-01-18 23:02:02  SVM v2                                                                                                                      complete  0.78468      None          \n",
      "titanic_model.csv                2020-01-13 22:50:55  voting predictor v3                                                                                                         complete  0.77990      None          \n",
      "titanic_model.csv                2020-01-13 22:44:44  Test voting predictor v2                                                                                                    complete  0.78947      None          \n",
      "submission_sv.csv                2020-01-12 22:58:56  4th attempt with SVM                                                                                                        complete  0.78947      None          \n",
      "submission_dt.csv                2020-01-12 22:55:04  3rd attempt with decision tree                                                                                              complete  0.72248      None          \n",
      "submission_rf.csv                2020-01-12 22:52:35  I tried with random forest optimized                                                                                        complete  0.75119      None          \n",
      "submission.csv                   2020-01-12 22:36:42  As my first challenge I use 5 supervised methods, and with 86% the accuracy I send my submission with Random Forest model.  complete  0.78947      None          \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submissions titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jovyan/.kaggle/kaggle.json'\n",
      " teamId  teamName                   submissionDate       score    \n",
      "-------  -------------------------  -------------------  -------  \n",
      "6015697  Jizhou Wei                 2020-12-16 03:13:08  1.00000  \n",
      "6023788  JaesikYang                 2020-12-17 00:11:13  1.00000  \n",
      "4364147  Börkapanda                 2021-02-12 19:23:04  1.00000  \n",
      "6027704  Eleven_Wang                2020-12-17 04:07:35  1.00000  \n",
      "6030190  Ease Gao                   2020-12-17 13:16:29  1.00000  \n",
      "5322915  Marcel Reis                2020-12-17 15:57:42  1.00000  \n",
      "5919487  Test 1                     2020-12-17 17:09:30  1.00000  \n",
      "5705094  Zeeshan Patel              2021-02-15 04:04:10  1.00000  \n",
      "5795033  Swapnils007                2020-12-18 04:59:08  1.00000  \n",
      "6036587  Rustin Shamloo             2020-12-18 15:54:41  1.00000  \n",
      "3749547  Adeyinka Michael Sotunde   2020-12-19 20:11:29  1.00000  \n",
      "5956259  RairiU                     2020-12-19 21:58:35  1.00000  \n",
      "6039146  shivanjay wagh             2020-12-22 11:46:47  1.00000  \n",
      "5896287  Cimbel16                   2020-12-20 06:11:39  1.00000  \n",
      "6036541  fedesoriano                2021-01-16 11:20:59  1.00000  \n",
      "6006583  Pavel Fedotov #2           2020-12-20 18:15:37  1.00000  \n",
      "6039687  Akash_1207                 2020-12-21 13:59:17  1.00000  \n",
      "6049638  Happy Singh #2             2020-12-21 16:54:17  1.00000  \n",
      "5766052  Kryif                      2020-12-22 05:11:51  1.00000  \n",
      "3936757  Vecheslav Eremeev          2021-03-12 05:37:45  1.00000  \n",
      "6043811  Moldovan Flavius           2020-12-22 14:35:30  1.00000  \n",
      "5354496  Vladimir Ryabchenko        2020-12-22 22:54:42  1.00000  \n",
      "5689160  JLUw6-417                  2020-12-23 11:40:10  1.00000  \n",
      "5687215  TwoAmigo                   2020-12-24 01:31:16  1.00000  \n",
      "4545151  SachGarg                   2020-12-24 07:03:19  1.00000  \n",
      "4872922  KHALED ABDELMOKIT          2020-12-24 20:05:57  1.00000  \n",
      "6049450  Anese_s                    2020-12-29 05:34:55  1.00000  \n",
      "6067355  Ivan Cherevko              2020-12-25 23:03:14  1.00000  \n",
      "6068364  Amit Mishra #2             2020-12-26 07:59:24  1.00000  \n",
      "6068373  Akash verma                2020-12-26 07:59:42  1.00000  \n",
      "6068377  Aditya Bhushan             2021-01-03 18:37:42  1.00000  \n",
      "6068401  Piyush Khare               2020-12-26 08:00:02  1.00000  \n",
      "6068363  Rishikesh Mishra MCA1      2020-12-26 08:00:44  1.00000  \n",
      "6068325  Muneshwar                  2020-12-28 10:56:12  1.00000  \n",
      "6068369  Digvijay Maurya            2020-12-26 08:01:38  1.00000  \n",
      "6068365  sakshi jais                2020-12-26 08:02:41  1.00000  \n",
      "6068407  Abhishek Yadav #3          2020-12-26 08:03:00  1.00000  \n",
      "6068385  Safiuddin Ansari MCA1 UoA  2020-12-26 08:04:09  1.00000  \n",
      "6068408  Vishesh Yadav MCA5         2020-12-26 08:04:48  1.00000  \n",
      "6068406  Akshat Srivastava MCA3     2020-12-26 08:07:53  1.00000  \n",
      "6068402  Nishant Srivastava         2020-12-26 08:10:21  1.00000  \n",
      "6068384  Srishti Vishwakarma        2020-12-26 08:11:35  1.00000  \n",
      "6068442  nahid_nisha                2020-12-26 08:19:43  1.00000  \n",
      "6068445  Ashish Chaubey             2020-12-26 08:23:58  1.00000  \n",
      "6068375  Nivedita verma11           2020-12-26 08:40:01  1.00000  \n",
      "6068570  Soamdutt Dwivedi           2020-12-26 08:53:43  1.00000  \n",
      "5519400  masato umemoto             2020-12-26 10:01:54  1.00000  \n",
      "6069054  Shweta Soni                2020-12-26 11:52:15  1.00000  \n",
      "6069170  TRIBHUWAN PASWAN           2020-12-26 12:29:44  1.00000  \n",
      "6069362  Neha Singh MCA 1           2020-12-26 13:55:15  1.00000  \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions leaderboard titanic -s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Ajuste de parámetros de otros estimadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
